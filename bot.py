import os
import json
import time
import re
import requests
import httpx
from bs4 import BeautifulSoup
from urllib.parse import urljoin

from telegram import (
    Update,
    ReplyKeyboardMarkup,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
)

from datetime import datetime, timedelta

from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

import gspread
from oauth2client.service_account import ServiceAccountCredentials

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOKEN = os.getenv("BOT_TOKEN")
APP_URL = (os.getenv("APP_URL") or "").strip()
CHANNEL_ID = (os.getenv("CHANNEL_ID") or "").strip()  # ì˜ˆ: @ì±„ë„ì•„ì´ë”” ë˜ëŠ” -100xxxxxxxxxxxx

# ğŸ”´ ì—¬ê¸°ë§Œ ë„¤ ë´‡ ìœ ì €ë„¤ì„ìœ¼ë¡œ ìˆ˜ì •í•˜ë©´ ë¨ (@ ë¹¼ê³ )
BOT_USERNAME = "castlive_bot"  # ì˜ˆ: @castlive_bot ì´ë¼ë©´ "castlive_bot"

# ğŸ”¹ ê´€ë¦¬ì ID ëª©ë¡ (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ëª… ê°€ëŠ¥) ì˜ˆ: "123456789,987654321"
_admin_ids_raw = os.getenv("ADMIN_IDS", "")
ADMIN_IDS = [
    int(x.strip())
    for x in _admin_ids_raw.split(",")
    if x.strip().isdigit()
]


def is_admin(update: Update) -> bool:
    """ì´ ëª…ë ¹ì–´ë¥¼ ëˆ„ê°€ í˜¸ì¶œí–ˆëŠ”ì§€ í™•ì¸í•´ì„œ, ê´€ë¦¬ìë©´ True ë¦¬í„´"""
    if not ADMIN_IDS:
        # ADMIN_IDSë¥¼ ì•ˆ ë„£ì—ˆìœ¼ë©´ ê·¸ëƒ¥ ëª¨ë‘ í—ˆìš© (í…ŒìŠ¤íŠ¸ìš©)
        return True
    user = update.effective_user
    return bool(user and user.id in ADMIN_IDS)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‚ ì§œ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_kst_now() -> datetime:
    """í•œêµ­ ì‹œê°„ ê¸°ì¤€ í˜„ì¬ ì‹œê° (UTC+9)"""
    return datetime.utcnow() + timedelta(hours=9)


def get_date_labels():
    """
    ì˜¤ëŠ˜ / ë‚´ì¼ ë‚ ì§œë¥¼ 'M.DD' í˜•ì‹ìœ¼ë¡œ ëŒë ¤ì¤Œ
    ì˜ˆ: ( '11.14', '11.15' )
    """
    now_kst = get_kst_now().date()
    today = now_kst
    tomorrow = now_kst + timedelta(days=1)

    today_str = f"{today.month}.{today.day:02d}"
    tomorrow_str = f"{tomorrow.month}.{tomorrow.day:02d}"
    return today_str, tomorrow_str


def get_menu_caption() -> str:
    """ë©”ì¸ ë©”ë‰´ ì„¤ëª… í…ìŠ¤íŠ¸ (ì˜¤ëŠ˜/ë‚´ì¼ ë‚ ì§œ ìë™ ë°˜ì˜)"""
    today_str, tomorrow_str = get_date_labels()
    return (
        "ğŸ“Œ ìŠ¤í¬ì¸  ì •ë³´&ë¶„ì„ ê³µìœ ë°© ë©”ë‰´ ì•ˆë‚´\n\n"
        "1ï¸âƒ£ ì‹¤ì‹œê°„ ë¬´ë£Œ ì¤‘ê³„ - GOAT-TV ë¼ì´ë¸Œ ì¤‘ê³„ ë°”ë¡œê°€ê¸°\n"
        f"2ï¸âƒ£ {today_str} ê²½ê¸° ë¶„ì„í”½ - ì¢…ëª©ë³„ë¡œ {today_str} ê²½ê¸° ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”\n"
        f"3ï¸âƒ£ {tomorrow_str} ê²½ê¸° ë¶„ì„í”½ - ì¢…ëª©ë³„ë¡œ {tomorrow_str} ê²½ê¸° ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”\n"
        "4ï¸âƒ£ ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ - ì£¼ìš” ì´ìŠˆ & ë‰´ìŠ¤ ìš”ì•½ ì •ë¦¬\n\n"
        "ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì›í•˜ëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡"
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¶„ì„/ë‰´ìŠ¤ ë°ì´í„° (ì˜ˆì‹œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ANALYSIS_TODAY = {
    "ì¶•êµ¬": [],
    "ë†êµ¬": [],
    "ì•¼êµ¬": [],
    "ë°°êµ¬": [],
}
ANALYSIS_TOMORROW = {
    "ì¶•êµ¬": [],
    "ë†êµ¬": [],
    "ì•¼êµ¬": [],
    "ë°°êµ¬": [],
}

ANALYSIS_DATA_MAP = {
    "today": ANALYSIS_TODAY,
    "tomorrow": ANALYSIS_TOMORROW,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# GOOGLE_SERVICE_KEY  : ì„œë¹„ìŠ¤ê³„ì • JSON ì „ì²´ (Render í™˜ê²½ë³€ìˆ˜)
# SPREADSHEET_ID      : êµ¬ê¸€ì‹œíŠ¸ ID (í™˜ê²½ë³€ìˆ˜)
# SHEET_TODAY_NAME    : ì˜¤ëŠ˜ íƒ­ ì´ë¦„ (ê¸°ë³¸ê°’ "today")
# SHEET_TOMORROW_NAME : ë‚´ì¼ íƒ­ ì´ë¦„ (ê¸°ë³¸ê°’ "tomorrow")

_gs_client = None  # gspread í´ë¼ì´ì–¸íŠ¸ ìºì‹œìš©


def get_gs_client():
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„œë¹„ìŠ¤ê³„ì • JSON ì½ì–´ì„œ gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    global _gs_client
    if _gs_client is not None:
        return _gs_client

    key_raw = os.getenv("GOOGLE_SERVICE_KEY")
    if not key_raw:
        print("[GSHEET] GOOGLE_SERVICE_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸ ì—°ë™ ê±´ë„ˆëœ€.")
        return None

    try:
        key_data = json.loads(key_raw)
    except Exception as e:
        print(f"[GSHEET] GOOGLE_SERVICE_KEY JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

    scope = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]

    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_data, scope)
    _gs_client = gspread.authorize(creds)
    print("[GSHEET] gspread ì¸ì¦ ì™„ë£Œ")
    return _gs_client


def summarize_text(text: str, max_len: int = 400) -> str:
    """
    ì•„ì£¼ ë‹¨ìˆœí•œ ìš”ì•½: ë¬¸ì¥ì„ ì˜ë¼ì„œ ì•ì—ì„œë¶€í„° max_lenê¹Œì§€ ìë¥´ëŠ” ë°©ì‹.
    """
    text = text.replace("\n", " ").strip()
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ëŒ€ì¶© ìë¥´ê¸° (í•œêµ­ì–´ë¼ ëŒ€ì¶© ë§ˆì¹¨í‘œ/ë‹¤/ìš” ê¸°ì¤€)
    sentences = re.split(r'(?<=[\.!?ë‹¤ìš”])\s+', text)
    result = ""
    for s in sentences:
        s = s.strip()
        if not s:
            continue
        if not result:
            candidate = s
        else:
            candidate = result + " " + s
        if len(candidate) > max_len:
            break
        result = candidate
    # ë„ˆë¬´ ì§§ìœ¼ë©´ ê·¸ëƒ¥ ì›ë¬¸ í•œ ë²ˆ ë” ì˜ë¼ì¤Œ
    if not result:
        result = text[:max_len]
    return result


def clean_daum_body_text(text: str) -> str:
    """
    ë‹¤ìŒ ë‰´ìŠ¤ ë³¸ë¬¸ì—ì„œ 'ìŒì„±ìœ¼ë¡œ ë“£ê¸°', ë²ˆì—­/ìš”ì•½ UI í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ ì œê±°.
    """
    if not text:
        return ""

    # 1ë‹¨ê³„: ë²ˆì—­/ìš”ì•½/ì–¸ì–´ì„ íƒ ë¸”ë¡ì´ ì‹œì‘ë˜ê¸° ì „ê¹Œì§€ë§Œ ì‚¬ìš©
    cut_keywords = [
        "ë²ˆì—­ ì„¤ì •",                      # ë²ˆì—­ ì„¤ì • ...
        "ë²ˆì—­ beta",                     # ë²ˆì—­ beta ...
        "Translated by",                # Translated by kakao ...
        "Now in translation",           # Now in translation ...
        "ìš”ì•½ë³¸ì´ ìë™ìš”ì•½",             # ìš”ì•½ ì•ˆë‚´ë¬¸
        "ê¸°ì‚¬ ì œëª©ê³¼ ì£¼ìš” ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ìš”ì•½í•œ ê²°ê³¼ì…ë‹ˆë‹¤",
    ]
    cut_pos = None
    for kw in cut_keywords:
        idx = text.find(kw)
        if idx != -1:
            if cut_pos is None or idx < cut_pos:
                cut_pos = idx

    if cut_pos is not None:
        text = text[:cut_pos]

    # 2ë‹¨ê³„: ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ë’¤ ì–¸ì–´ ëª©ë¡ ë“± ë¶ˆí•„ìš”í•œ ì¤„ ì œê±°
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    blacklist = [
        "ìŒì„±ìœ¼ë¡œ ë“£ê¸°",
        "ìŒì„± ì¬ìƒ",
        "ìŒì„±ì¬ìƒ ì„¤ì •",
        "ë²ˆì—­ ì„¤ì •",
        "ë²ˆì—­ beta",
        "Translated by",
        "ì „ì²´ ë§¥ë½ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ë³¸ë¬¸ ë³´ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
        "ìš”ì•½ë¬¸ì´ë¯€ë¡œ ì¼ë¶€ ë‚´ìš©ì´ ìƒëµë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        # ì–¸ì–´ ëª©ë¡ í‚¤ì›Œë“œ
        "í•œêµ­ì–´ - English",
        "í•œêµ­ì–´ - ì˜ì–´",
        "English",
        "æ—¥æœ¬èª",
        "ç®€ä½“ä¸­æ–‡",
        "Deutsch",
        "Ğ ÑƒÑÑĞºĞ¸Ğ¹",
        "EspaÃ±ol",
        "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "bahasa Indonesia",
        "à¸ à¸²à¸©à¸²à¹„à¸—à¸¢",
        "TÃ¼rkÃ§e",
    ]

    clean_lines = []
    for l in lines:
        if any(b in l for b in blacklist):
            continue
        clean_lines.append(l)

    return " ".join(clean_lines)

def crawl_naver_soccer(max_count: int = 5) -> list[dict]:
    """
    (ë‹¤ìŒ ìŠ¤í¬ì¸  í•´ì™¸ì¶•êµ¬) ìµœì‹  ë‰´ìŠ¤ ì¼ë¶€ë¥¼ í¬ë¡¤ë§í•´ì„œ
    [ {title, summary, url}, ... ] ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    articles: list[dict] = []

    # â”€â”€ 1) ë‹¤ìŒ harmony JSON APIì—ì„œ í•´ì™¸ì¶•êµ¬ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° â”€â”€
    base_url = "https://sports.daum.net/media-api/harmony/contents.json"

    # í•œêµ­ ì‹œê°„ ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ
    today_kst = get_kst_now().date()
    ymd = today_kst.strftime("%Y%m%d")
    create_dt = f"{ymd}000000~{ymd}235959"

    # discoveryTag[0] ê°’ (í•´ì™¸ì¶•êµ¬ ì¹´í…Œê³ ë¦¬ ID: 100032)
    discovery_tag_value = json.dumps(
        {
            "group": "media",
            "key": "defaultCategoryId3",
            "value": "100032",
        },
        ensure_ascii=False,
    )

    params = {
        "page": 0,
        "consumerType": "HARMONY",
        "status": "SERVICE",
        "createDt": create_dt,
        "size": max_count if max_count > 0 else 5,
        "discoveryTag[0]": discovery_tag_value,
    }

    try:
        resp = requests.get(base_url, headers=headers, params=params, timeout=10)
        resp.raise_for_status()
    except Exception as e:
        print(f"[CRAWLER] ë‹¤ìŒ harmony API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return articles

    try:
        data = resp.json()
    except Exception as e:
        print(f"[CRAWLER] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return articles

    # contents ë¦¬ìŠ¤íŠ¸ ì°¾ê¸° (êµ¬ì¡° ë³€í™”ì— ëŒ€ë¹„í•œ ë°©ì–´ ì½”ë“œ)
    contents = None
    if isinstance(data, dict):
        contents = data.get("contents")
        if contents is None:
            inner = data.get("data") or data.get("result") or data.get("body")
            if isinstance(inner, dict):
                contents = inner.get("contents") or inner.get("list") or inner.get("items")
    elif isinstance(data, list):
        contents = data

    if not contents:
        print(
            "[CRAWLER] JSONì—ì„œ contents ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            f"type={type(data)}, keys={list(data.keys()) if isinstance(data, dict) else 'N/A'}",
        )
        return articles

    # â”€â”€ 2) JSONì—ì„œ ì œëª© + ë§í¬ ì¶”ì¶œ â”€â”€
    link_items: list[dict] = []
    for item in contents:
        if not isinstance(item, dict):
            continue

        title = (
            item.get("title")
            or item.get("contentTitle")
            or item.get("headline")
            or item.get("name")
        )

        url = (
            item.get("contentUrl")
            or item.get("permalink")
            or item.get("url")
            or item.get("link")
        )

        if not title or not url:
            continue

        title = str(title).strip()
        url = str(url).strip()

        # ìƒëŒ€ê²½ë¡œë©´ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜
        if url.startswith("/"):
            url = urljoin("https://sports.daum.net", url)

        link_items.append({"title": title, "url": url})

        if len(link_items) >= max_count:
            break

    if not link_items:
        print("[CRAWLER] ì œëª©/URL ì¶”ì¶œ ì‹¤íŒ¨ (contents êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„±)")
        return articles

    # â”€â”€ 3) ê° ê¸°ì‚¬ í˜ì´ì§€ì—ì„œ ë³¸ë¬¸ ê¸ê³  ìš”ì•½ â”€â”€
    for it in link_items:
        link = it["url"]
        title = it["title"]

        try:
            resp2 = requests.get(link, headers=headers, timeout=10)
            resp2.raise_for_status()
            s2 = BeautifulSoup(resp2.text, "html.parser")

            body_el = (
                s2.select_one("div#harmonyContainer")
                or s2.select_one("div#mArticle div#harmonyContainer")
                or s2.select_one("div#mArticle")
                or s2.find("article")
                or s2.body
            )

            if not body_el:
                print(f"[CRAWLER] ë³¸ë¬¸ íƒœê·¸ ëª» ì°¾ìŒ: {link}")
                continue

            raw_body_text = body_el.get_text("\n", strip=True)
            clean_body_text = clean_daum_body_text(raw_body_text)
            summary = summarize_text(clean_body_text, max_len=400)

            articles.append(
                {
                    "title": title,
                    "summary": summary,
                    "url": link,
                }
            )

        except Exception as e:
            print(f"[CRAWLER] ê¸°ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ({link}): {e}")
            continue

    return articles


def _load_analysis_sheet(sh, sheet_name: str) -> dict:
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ í•œ íƒ­(today / tomorrow)ì„ ì½ì–´ì„œ
    { sport: [ {id,title,summary}, ... ] } êµ¬ì¡°ë¡œ ë³€í™˜

    ì‹œíŠ¸ ì»¬ëŸ¼ êµ¬ì¡° (1í–‰ í—¤ë” ê¸°ì¤€):
    Aì—´: sport   (ì˜ˆ: ì¶•êµ¬/ë†êµ¬/ì•¼êµ¬/ë°°êµ¬)
    Bì—´: id      (botì—ì„œ ì“¸ ê³ ìœ  id, ë¹„ì›Œë‘ë©´ ìë™ ìƒì„±)
    Cì—´: title   (ë²„íŠ¼ì— ë³´ì´ëŠ” ì œëª©)
    Dì—´: summary (ë¶„ì„ ë³¸ë¬¸)
    """
    try:
        ws = sh.worksheet(sheet_name)
    except Exception as e:
        print(f"[GSHEET] ì‹œíŠ¸ '{sheet_name}' ì—´ê¸° ì‹¤íŒ¨: {e}")
        return {}

    rows = ws.get_all_values()
    if not rows:
        return {}

    # í—¤ë” íŒŒì‹± (ì²« í–‰)
    header = rows[0]
    # ê¸°ë³¸ ì¸ë±ìŠ¤
    idx_sport = 0
    idx_id = 1
    idx_title = 2
    idx_summary = 3

    def safe_index(name, default):
        try:
            return header.index(name)
        except ValueError:
            return default

    # í—¤ë”ì— 'sport', 'id', 'title', 'summary' ê¸€ìê°€ ìˆìœ¼ë©´ ê·¸ ìœ„ì¹˜ ì‚¬ìš©
    idx_sport = safe_index("sport", idx_sport)
    idx_id = safe_index("id", idx_id)
    idx_title = safe_index("title", idx_title)
    idx_summary = safe_index("summary", idx_summary)

    data: dict[str, list[dict]] = {}

    for row in rows[1:]:  # ë°ì´í„° í–‰
        if len(row) <= idx_title:
            continue

        sport = (row[idx_sport] if len(row) > idx_sport else "").strip()
        if not sport:
            continue

        item_id = (row[idx_id] if len(row) > idx_id else "").strip()
        title = (row[idx_title] if len(row) > idx_title else "").strip()
        summary = (row[idx_summary] if len(row) > idx_summary else "").strip()

        if not title:
            continue

        # id ì—†ìœ¼ë©´ ìë™ ìƒì„±
        if not item_id:
            cur_len = len(data.get(sport, []))
            item_id = f"{sport}_{cur_len + 1}"

        entry = {
            "id": item_id,
            "title": title,
            "summary": summary,
        }
        data.setdefault(sport, []).append(entry)

    return data


def reload_analysis_from_sheet():
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ today / tomorrow íƒ­ì„ ì½ì–´ì„œ
    ANALYSIS_TODAY / ANALYSIS_TOMORROW / ANALYSIS_DATA_MAP ê°±ì‹ 
    """
    global ANALYSIS_TODAY, ANALYSIS_TOMORROW, ANALYSIS_DATA_MAP

    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not client or not spreadsheet_id:
        print("[GSHEET] ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” SPREADSHEET_ID ì—†ìŒ â†’ ê¸°ì¡´ í•˜ë“œì½”ë”© ë°ì´í„° ì‚¬ìš©")
        return

    try:
        sh = client.open_by_key(spreadsheet_id)
    except Exception as e:
        print(f"[GSHEET] ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° ì‹¤íŒ¨: {e}")
        return

    sheet_today_name = os.getenv("SHEET_TODAY_NAME", "today")
    sheet_tomorrow_name = os.getenv("SHEET_TOMORROW_NAME", "tomorrow")

    print(f"[GSHEET] '{sheet_today_name}' / '{sheet_tomorrow_name}' íƒ­ì—ì„œ ë¶„ì„ ë°ì´í„° ë¡œë”© ì‹œë„")

    try:
        today_data = _load_analysis_sheet(sh, sheet_today_name)
        tomorrow_data = _load_analysis_sheet(sh, sheet_tomorrow_name)
    except Exception as e:
        print(f"[GSHEET] ì‹œíŠ¸ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return

    ANALYSIS_TODAY = today_data
    ANALYSIS_TOMORROW = tomorrow_data

    ANALYSIS_DATA_MAP = {
        "today": ANALYSIS_TODAY,
        "tomorrow": ANALYSIS_TOMORROW,
    }

    print("[GSHEET] ANALYSIS_TODAY / ANALYSIS_TOMORROW ê°±ì‹  ì™„ë£Œ")


NEWS_DATA = {}


def _load_news_sheet(sh, sheet_name: str) -> dict:
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë‰´ìŠ¤ íƒ­ì„ ì½ì–´ì„œ
    {
        sport: [ {id,title,summary}, ... ]
    } êµ¬ì¡°ë¡œ ë³€í™˜

    ì‹œíŠ¸ ì»¬ëŸ¼ êµ¬ì¡° (1í–‰ í—¤ë” ê¸°ì¤€):
    Aì—´: sport
    Bì—´: id
    Cì—´: title
    Dì—´: summary
    """
    try:
        ws = sh.worksheet(sheet_name)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ì‹œíŠ¸ '{sheet_name}' ì—´ê¸° ì‹¤íŒ¨: {e}")
        return {}

    rows = ws.get_all_values()
    if not rows:
        return {}

    header = rows[0]

    # ê¸°ë³¸ index
    idx_sport = 0
    idx_id = 1
    idx_title = 2
    idx_summary = 3

    # í—¤ë” ê¸°ë°˜ ë™ì  ë§¤ì¹­
    def safe_index(name, default):
        try:
            return header.index(name)
        except ValueError:
            return default

    idx_sport = safe_index("sport", idx_sport)
    idx_id = safe_index("id", idx_id)
    idx_title = safe_index("title", idx_title)
    idx_summary = safe_index("summary", idx_summary)

    data: dict[str, list[dict]] = {}

    for row in rows[1:]:
        if len(row) <= idx_title:
            continue

        sport = (row[idx_sport] if len(row) > idx_sport else "").strip()
        if not sport:
            continue

        item_id = (row[idx_id] if len(row) > idx_id else "").strip()
        title = (row[idx_title] if len(row) > idx_title else "").strip()
        summary = (row[idx_summary] if len(row) > idx_summary else "").strip()

        if not title:
            continue

        # id ë¹„ì–´ ìˆìœ¼ë©´ ìë™ ìƒì„±
        if not item_id:
            cur_len = len(data.get(sport, []))
            item_id = f"{sport}_news_{cur_len + 1}"

        entry = {
            "id": item_id,
            "title": title,
            "summary": summary,
        }
        data.setdefault(sport, []).append(entry)

    return data


def reload_news_from_sheet():
    """êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë‰´ìŠ¤ íƒ­ì„ ì½ì–´ì„œ NEWS_DATA ê°±ì‹ """
    global NEWS_DATA
    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not client or not spreadsheet_id:
        print("[GSHEET] ë‰´ìŠ¤ìš© SPREADSHEET ì—°ë™ ì‹¤íŒ¨ â†’ ê¸°ì¡´ í•˜ë“œì½”ë”© NEWS_DATA ì‚¬ìš©.")
        return

    try:
        sh = client.open_by_key(spreadsheet_id)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° ì‹¤íŒ¨: {e}")
        return

    sheet_news_name = os.getenv("SHEET_NEWS_NAME", "news")
    print(f"[GSHEET] '{sheet_news_name}' íƒ­ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì‹œë„")

    try:
        news_data = _load_news_sheet(sh, sheet_news_name)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ì‹œíŠ¸ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return

    NEWS_DATA = news_data
    print("[GSHEET] NEWS_DATA ê°±ì‹  ì™„ë£Œ")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‚¤ë³´ë“œ/ë©”ë‰´ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_reply_keyboard() -> ReplyKeyboardMarkup:
    """ë´‡ 1:1 í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨ í•˜ë‹¨ í‚¤ë³´ë“œ"""
    menu = [
        ["ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°", "ë„ì›€ë§"],
    ]
    return ReplyKeyboardMarkup(menu, resize_keyboard=True)


def build_main_inline_menu() -> InlineKeyboardMarkup:
    """
    ë©”ì¸ ì¸ë¼ì¸ ë©”ë‰´ (ì±„ë„/ë¯¸ë¦¬ë³´ê¸° ê³µí†µ)
    ì±„ë„ì—ì„œëŠ” ì´ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê°ì ë´‡ DMìœ¼ë¡œ ì´ë™í•˜ê²Œ í•¨.
    """
    today_str, tomorrow_str = get_date_labels()

    buttons = [
        [InlineKeyboardButton("ì‹¤ì‹œê°„ ë¬´ë£Œ ì¤‘ê³„", url="https://goat-tv.com")],
        [
            InlineKeyboardButton(
                f"{today_str} ê²½ê¸° ë¶„ì„í”½",
                url=f"https://t.me/{BOT_USERNAME}?start=today",
            )
        ],
        [
            InlineKeyboardButton(
                f"{tomorrow_str} ê²½ê¸° ë¶„ì„í”½",
                url=f"https://t.me/{BOT_USERNAME}?start=tomorrow",
            )
        ],
        [
            InlineKeyboardButton(
                "ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½",
                url=f"https://t.me/{BOT_USERNAME}?start=news",
            )
        ],
    ]
    return InlineKeyboardMarkup(buttons)


def build_analysis_category_menu(key: str) -> InlineKeyboardMarkup:
    # key = "today" or "tomorrow"
    buttons = [
        [InlineKeyboardButton("âš½ï¸ì¶•êµ¬âš½ï¸", callback_data=f"analysis_cat:{key}:ì¶•êµ¬")],
        [InlineKeyboardButton("ğŸ€ë†êµ¬ğŸ€", callback_data=f"analysis_cat:{key}:ë†êµ¬")],
        [InlineKeyboardButton("âš¾ï¸ì•¼êµ¬âš¾ï¸", callback_data=f"analysis_cat:{key}:ì•¼êµ¬")],
        [InlineKeyboardButton("ğŸë°°êµ¬ğŸ", callback_data=f"analysis_cat:{key}:ë°°êµ¬")],
        [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
    ]
    return InlineKeyboardMarkup(buttons)


def build_analysis_match_menu(key: str, sport: str) -> InlineKeyboardMarkup:
    """ì¢…ëª© ì„ íƒ í›„ â†’ í•´ë‹¹ ì¢…ëª© ê²½ê¸° ë¦¬ìŠ¤íŠ¸ ë©”ë‰´"""
    items = ANALYSIS_DATA_MAP.get(key, {}).get(sport, [])
    buttons = []
    for item in items:
        cb = f"match:{key}:{sport}:{item['id']}"
        buttons.append([InlineKeyboardButton(item["title"], callback_data=cb)])

    buttons.append([InlineKeyboardButton("â—€ ì¢…ëª© ì„ íƒìœ¼ë¡œ", callback_data=f"analysis_root:{key}")])
    buttons.append([InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")])
    return InlineKeyboardMarkup(buttons)


def build_news_category_menu() -> InlineKeyboardMarkup:
    """ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ â†’ ì¢…ëª© ì„ íƒ ë©”ë‰´"""
    buttons = [
        [InlineKeyboardButton("âš½ï¸ì¶•êµ¬ ë‰´ìŠ¤âš½ï¸", callback_data="news_cat:ì¶•êµ¬")],
        [InlineKeyboardButton("ğŸ€ë†êµ¬ ë‰´ìŠ¤ğŸ€", callback_data="news_cat:ë†êµ¬")],
        [InlineKeyboardButton("âš¾ï¸ì•¼êµ¬ ë‰´ìŠ¤âš¾ï¸", callback_data="news_cat:ì•¼êµ¬")],
        [InlineKeyboardButton("ğŸë°°êµ¬ ë‰´ìŠ¤ğŸ", callback_data="news_cat:ë°°êµ¬")],
        [InlineKeyboardButton("ê¸°íƒ€ì¢…ëª© ë‰´ìŠ¤", callback_data="news_cat:ê¸°íƒ€ì¢…")],
        [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
    ]
    return InlineKeyboardMarkup(buttons)


def build_news_list_menu(sport: str) -> InlineKeyboardMarkup:
    """ì¢…ëª© ì„ íƒ í›„ â†’ í•´ë‹¹ ì¢…ëª© ë‰´ìŠ¤ ì œëª© ë¦¬ìŠ¤íŠ¸ ë©”ë‰´"""
    items = NEWS_DATA.get(sport, [])
    buttons = []
    for item in items:
        cb = f"news_item:{sport}:{item['id']}"
        buttons.append([InlineKeyboardButton(item["title"], callback_data=cb)])

    buttons.append([InlineKeyboardButton("â—€ ì¢…ëª© ì„ íƒìœ¼ë¡œ", callback_data="news_root")])
    buttons.append([InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")])
    return InlineKeyboardMarkup(buttons)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ: ë©”ì¸ ë©”ë‰´ ë³´ë‚´ëŠ” í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def send_main_menu(chat_id: int | str, context: ContextTypes.DEFAULT_TYPE, preview: bool = False):
    """
    ì±„ë„/DM ê³µí†µìœ¼ë¡œ 'í…ìŠ¤íŠ¸ + ë©”ì¸ ë©”ë‰´ ë²„íŠ¼' ì „ì†¡.
    """
    msg = await context.bot.send_message(
        chat_id=chat_id,
        text=get_menu_caption(),
        reply_markup=build_main_inline_menu(),
    )
    return msg


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•¸ë“¤ëŸ¬ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1) /start â€“ DMì—ì„œ ì±„ë„ê³¼ ë™ì¼í•œ ë ˆì´ì•„ì›ƒ or ë°”ë¡œ ë©”ë‰´ ì§„ì…
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    args = context.args
    mode = args[0] if args else None

    today_str, tomorrow_str = get_date_labels()

    # ì˜¤ëŠ˜ ë¶„ì„ ë²„íŠ¼
    if mode == "today":
        await update.message.reply_text(
            f"{today_str} ê²½ê¸° ë¶„ì„í”½ ë©”ë‰´ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_analysis_category_menu("today"),
        )
        return

    # ë‚´ì¼ ë¶„ì„ ë²„íŠ¼
    if mode == "tomorrow":
        await update.message.reply_text(
            f"{tomorrow_str} ê²½ê¸° ë¶„ì„í”½ ë©”ë‰´ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_analysis_category_menu("tomorrow"),
        )
        return

    if mode == "news":
        await update.message.reply_text(
            "ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_news_category_menu(),
        )
        return

    # ê·¸ ì™¸: DMì—ì„œ ì „ì²´ ë ˆì´ì•„ì›ƒ ë¯¸ë¦¬ë³´ê¸°
    await update.message.reply_text(
        "ìŠ¤í¬ì¸ ë´‡ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ì—ëŠ” ì±„ë„ì— ì˜¬ë¼ê°ˆ ë©”ë‰´ì™€ ë™ì¼í•œ ë ˆì´ì•„ì›ƒ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë³´ì—¬ì¤„ê²Œ.\n"
        "ì‹¤ì œ ì±„ë„ ë°°í¬ëŠ” /publish ëª…ë ¹ìœ¼ë¡œ ì§„í–‰í•˜ë©´ ë¼.",
        reply_markup=build_reply_keyboard(),
    )

    await send_main_menu(chat_id, context, preview=True)


async def myid(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    await update.message.reply_text(f"ë‹¹ì‹ ì˜ í…”ë ˆê·¸ë¨ ID: {uid}")


# 2) DM í…ìŠ¤íŠ¸ ì²˜ë¦¬ â€“ ê°„ë‹¨ í…ŒìŠ¤íŠ¸ìš©
async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    if "ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°" in text:
        await start(update, context)
    elif "ë„ì›€ë§" in text:
        await update.message.reply_text(
            "/start : ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°\n"
            "/publish : ì±„ë„ì— ë©”ë‰´ ì „ì†¡ + ìƒë‹¨ ê³ ì •"
        )
    else:
        await update.message.reply_text("ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°ëŠ” /start ë˜ëŠ” 'ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")


# 3) /publish â€“ ì±„ë„ë¡œ ë©”ë‰´ ë³´ë‚´ê³  ìƒë‹¨ ê³ ì •
async def publish(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    if not CHANNEL_ID:
        await update.message.reply_text("CHANNEL_IDê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. Render í™˜ê²½ë³€ìˆ˜ì— CHANNEL_IDë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return

    # ê¸°ì¡´ ê³ ì • ë©”ì‹œì§€ í•´ì œ (ì„ íƒ)
    try:
        await context.bot.unpin_all_chat_messages(CHANNEL_ID)
    except Exception:
        pass

    # ì±„ë„ì— DMê³¼ ë™ì¼í•œ ë©”ë‰´ ì „ì†¡
    msg = await send_main_menu(CHANNEL_ID, context, preview=False)

    # ë°©ê¸ˆ ë³´ë‚¸ ë©”ë‰´ ë©”ì‹œì§€ ìƒë‹¨ ê³ ì •
    await context.bot.pin_chat_message(
        chat_id=CHANNEL_ID,
        message_id=msg.message_id,
        disable_notification=True,
    )

    await update.message.reply_text("ì±„ë„ì— ë©”ë‰´ë¥¼ ì˜¬ë¦¬ê³  ìƒë‹¨ì— ê³ ì •í–ˆìŠµë‹ˆë‹¤ âœ…")


# 5) /syncsheet â€“ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë¶„ì„ ë°ì´í„° ë‹¤ì‹œ ë¡œë”©
async def syncsheet(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    try:
        reload_analysis_from_sheet()
        reload_news_from_sheet()
        await update.message.reply_text("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë¶„ì„ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤ âœ…")
    except Exception as e:
        await update.message.reply_text(f"êµ¬ê¸€ì‹œíŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# ğŸ”¹ 4) /rollover â€“ ë‚´ì¼ ë¶„ì„ â†’ ì˜¤ëŠ˜ ë¶„ì„ìœ¼ë¡œ ë³µì‚¬
async def rollover(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if client and spreadsheet_id:
        try:
            sh = client.open_by_key(spreadsheet_id)

            sheet_today_name = os.getenv("SHEET_TODAY_NAME", "today")
            sheet_tomorrow_name = os.getenv("SHEET_TOMORROW_NAME", "tomorrow")

            ws_today = sh.worksheet(sheet_today_name)
            ws_tomorrow = sh.worksheet(sheet_tomorrow_name)

            # tomorrow íƒ­ ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            rows = ws_tomorrow.get_all_values()

            if rows:
                # 1-1) today íƒ­ì„ tomorrow ë‚´ìš©ìœ¼ë¡œ í†µì§¸ë¡œ ë®ì–´ì“°ê¸°
                ws_today.clear()
                ws_today.update("A1", rows)

                # 1-2) tomorrow íƒ­ì€ í—¤ë”ë§Œ ë‚¨ê¸°ê³  ë¹„ìš°ê¸°
                header = rows[0]
                ws_tomorrow.clear()
                ws_tomorrow.update("A1", [header])
            else:
                print("[GSHEET] tomorrow íƒ­ì— ë°ì´í„°ê°€ ì—†ì–´ ì‹œíŠ¸ ë¡¤ì˜¤ë²„ëŠ” ìƒëµí•©ë‹ˆë‹¤.")

        except Exception as e:
            print(f"[GSHEET] ë¡¤ì˜¤ë²„ ì¤‘ ì‹œíŠ¸ ë³µì‚¬ ì‹¤íŒ¨: {e}")

    else:
        print("[GSHEET] í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” SPREADSHEET_ID ì—†ìŒ â†’ ì‹œíŠ¸ ë¡¤ì˜¤ë²„ëŠ” ê±´ë„ˆëœ€.")

    reload_analysis_from_sheet()

    await update.message.reply_text(
        "âœ… ë¡¤ì˜¤ë²„ ì™„ë£Œ!\n"
        "êµ¬ê¸€ì‹œíŠ¸ 'tomorrow' íƒ­ ë‚´ìš©ì„ 'today' íƒ­ìœ¼ë¡œ ë³µì‚¬í–ˆê³ ,\n"
        "'tomorrow' íƒ­ì€ í—¤ë”ë§Œ ë‚¨ê¸°ê³  ì´ˆê¸°í™”í–ˆì–´.\n\n"
        "ì´ì œ ì˜¤ëŠ˜ ê²½ê¸° ë¶„ì„ì€ 'today' íƒ­ì—ì„œ, ë‚´ì¼ ê²½ê¸°ëŠ” 'tomorrow' íƒ­ì—ì„œ ì‘ì„±í•˜ë©´ ë¼."
    )


def simple_summarize(text: str, max_chars: int = 400) -> str:
    """
    ì•„ì£¼ ë‹¨ìˆœ ìš”ì•½: ë¬¸ì¥ ì‚¬ì´ ê³µë°± ì •ë¦¬ í›„,
    max_chars ì•ˆìª½ì—ì„œ 'ë‹¤.' ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ì„œ ë°˜í™˜.
    """
    if not text:
        return ""

    text = re.sub(r"\s+", " ", text).strip()

    if len(text) <= max_chars:
        return text

    cut = text.rfind("ë‹¤.", 0, max_chars)
    if cut != -1:
        return text[: cut + 2]

    return text[:max_chars] + "..."


async def fetch_daum_worldsoccer_json(client: httpx.AsyncClient) -> list[dict]:
    """
    ë‹¤ìŒ ìŠ¤í¬ì¸  í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ JSON ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    Daum ë‚´ë¶€ harmony API ì‚¬ìš©.
    """
    base_url = "https://sports.daum.net/media-api/harmony/contents.json"

    today_kst = get_kst_now().date()
    ymd = today_kst.strftime("%Y%m%d")
    create_dt = f"{ymd}000000~{ymd}235959"

    discovery_tag_value = json.dumps({
        "group": "media",
        "key": "defaultCategoryId3",
        "value": "100032",      # í•´ì™¸ì¶•êµ¬ ì¹´í…Œê³ ë¦¬ ID
    }, ensure_ascii=False)

    params = {
        "page": 0,
        "consumerType": "HARMONY",
        "status": "SERVICE",
        "createDt": create_dt,
        "size": 20,
        "discoveryTag[0]": discovery_tag_value,
    }

    r = await client.get(base_url, params=params, timeout=10.0)
    r.raise_for_status()
    data = r.json()

    contents = None
    if isinstance(data, dict):
        contents = data.get("contents")
        if contents is None:
            inner = data.get("data") or data.get("result") or data.get("body")
            if isinstance(inner, dict):
                contents = inner.get("contents") or inner.get("list") or inner.get("items")
    elif isinstance(data, list):
        contents = data

    if not contents:
        print("[CRAWL][DAUM] JSON êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìµœìƒìœ„ í‚¤:", list(data.keys()) if isinstance(data, dict) else type(data))
        return []

    return contents


async def fetch_article_body(client: httpx.AsyncClient, url: str) -> str:
    """
    (ì˜ˆì „ ë„¤ì´ë²„ìš©) ë‰´ìŠ¤ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ.
    í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ ë‚¨ê²¨ë‘ .
    """
    try:
        r = await client.get(url, timeout=10.0, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
    except Exception as e:
        print(f"[CRAWL][ARTICLE] ìš”ì²­ ì‹¤íŒ¨: {url} / {e}")
        return ""

    soup = BeautifulSoup(r.text, "html.parser")

    body = soup.select_one("#newsEndContents")
    if body:
        return body.get_text("\n", strip=True)

    body = soup.select_one("#newsEndBody")
    if body:
        return body.get_text("\n", strip=True)

    body = soup.select_one("#dic_area")
    if body:
        return body.get_text("\n", strip=True)

    print(f"[CRAWL][ARTICLE] ë³¸ë¬¸ ì…€ë ‰í„° ë§¤ì¹˜ ì‹¤íŒ¨: {url}")
    return ""


async def crawlsoccer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # ê´€ë¦¬ìë§Œ ì‚¬ìš©
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    await update.message.reply_text("ë‹¤ìŒìŠ¤í¬ì¸  í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")

    try:
        async with httpx.AsyncClient(
            headers={"User-Agent": "Mozilla/5.0"},
            follow_redirects=True,
        ) as client:

            contents = await fetch_daum_worldsoccer_json(client)

            if not contents:
                await update.message.reply_text("í•´ì™¸ì¶•êµ¬ JSON ë°ì´í„°ì—ì„œ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return

            articles = []

            # 2) JSONì—ì„œ ì œëª© + ê¸°ì‚¬ URL ì¶”ì¶œ
            for item in contents:
                title = (
                    item.get("title")
                    or item.get("contentTitle")
                    or item.get("headline")
                    or item.get("name")
                )

                url = (
                    item.get("contentUrl")
                    or item.get("permalink")
                    or item.get("url")
                    or item.get("link")
                )

                if not title or not url:
                    continue

                title = str(title).strip()
                url = str(url).strip()

                if url.startswith("/"):
                    url = urljoin("https://sports.daum.net", url)

                articles.append({"title": title, "link": url})

                if len(articles) >= 10:
                    break

            if not articles:
                await update.message.reply_text("JSONì€ ë°›ì•˜ì§€ë§Œ, ì œëª©/URL ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return

            # 3) ê° ê¸°ì‚¬ í˜ì´ì§€ ë“¤ì–´ê°€ì„œ ë³¸ë¬¸ í¬ë¡¤ë§ + ìš”ì•½
            for art in articles:
                try:
                    r2 = await client.get(art["link"], timeout=10.0)
                    r2.raise_for_status()
                    s2 = BeautifulSoup(r2.text, "html.parser")

                    body_el = (
                        s2.select_one("div#harmonyContainer")
                        or s2.select_one("div#mArticle div#harmonyContainer")
                        or s2.select_one("div#mArticle")
                        or s2.find("article")
                        or s2.body
                    )

                    if body_el:
                        body_text = body_el.get_text("\n", strip=True)
                    else:
                        body_text = ""

                    clean_text = clean_daum_body_text(body_text)
                    art["summary"] = simple_summarize(clean_text, max_chars=400)

                except Exception as e:
                    print(f"[CRAWL][DAUM] ê¸°ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ({art['link']}): {e}")
                    art["summary"] = "(ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨)"

    except Exception as e:
        await update.message.reply_text(f"ìš”ì²­ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # 4) êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥
    client_gs = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not (client_gs and spreadsheet_id):
        await update.message.reply_text(
            "êµ¬ê¸€ì‹œíŠ¸ ì„¤ì •(GOOGLE_SERVICE_KEY ë˜ëŠ” SPREADSHEET_ID)ì´ ì—†ì–´ ì‹œíŠ¸ì— ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )
        return

    try:
        sh = client_gs.open_by_key(spreadsheet_id)
        ws = sh.worksheet(os.getenv("SHEET_NEWS_NAME", "news"))
    except Exception as e:
        await update.message.reply_text(f"ë‰´ìŠ¤ ì‹œíŠ¸ë¥¼ ì—´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        return

    rows_to_append = []
    for art in articles:
        rows_to_append.append([
            "ì¶•êµ¬",          # sport
            "",             # id (ë¹„ì›Œë‘ë©´ ë‚˜ì¤‘ì— ìë™ ìƒì„±)
            art["title"],   # title
            art["summary"], # summary
        ])

    try:
        ws.append_rows(rows_to_append, value_input_option="RAW")
    except Exception as e:
        await update.message.reply_text(f"ì‹œíŠ¸ ì“°ê¸° ì˜¤ë¥˜: {e}")
        return

    await update.message.reply_text(
        f"ë‹¤ìŒìŠ¤í¬ì¸  í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ {len(rows_to_append)}ê±´ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
        "/syncsheet ë¡œ í…”ë ˆê·¸ë¨ ë©”ë‰´ë¥¼ ê°±ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )


# 4) ì¸ë¼ì¸ ë²„íŠ¼ ì½œë°± ì²˜ë¦¬ (ë¶„ì„/ë‰´ìŠ¤ íŒì—…)
async def on_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    data = q.data or ""
    await q.answer()  # ê¸°ë³¸ ë¡œë”©í‘œì‹œ ì œê±°

    # ë©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°€ê¸°
    if data == "back_main":
        await q.edit_message_reply_markup(reply_markup=build_main_inline_menu())
        return

    # ë¶„ì„í”½ ë£¨íŠ¸: ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    if data.startswith("analysis_root:"):
        _, key = data.split(":", 1)          # today / tomorrow
        await q.edit_message_reply_markup(reply_markup=build_analysis_category_menu(key))
        return

    # ë¶„ì„í”½ â€“ ì¢…ëª© ì„ íƒ
    if data.startswith("analysis_cat:"):
        _, key, sport = data.split(":", 2)
        await q.edit_message_reply_markup(reply_markup=build_analysis_match_menu(key, sport))
        return

    # ë¶„ì„í”½ â€“ ê°œë³„ ê²½ê¸° ì„ íƒ â†’ ì±„íŒ…ì°½ì— ë¶„ì„ê¸€ ì „ì†¡
    if data.startswith("match:"):
        _, key, sport, match_id = data.split(":", 3)
        items = ANALYSIS_DATA_MAP.get(key, {}).get(sport, [])

        title = "ì„ íƒí•œ ê²½ê¸°"
        summary = "í•´ë‹¹ ê²½ê¸° ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        for item in items:
            if item["id"] == match_id:
                title = item["title"]
                summary = item["summary"]
                break

        text = f"ğŸ“Œ ê²½ê¸° ë¶„ì„ â€“ {title}\n\n{summary}"

        buttons = [
            [InlineKeyboardButton("ğŸ“º ìŠ¤í¬ì¸  ë¬´ë£Œ ì¤‘ê³„", url="https://goat-tv.com")],
            [InlineKeyboardButton("ğŸ“ ë¶„ì„ê¸€ ë” ë³´ê¸°", callback_data=f"analysis_root:{key}")],
            [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
        ]

        await q.message.reply_text(text, reply_markup=InlineKeyboardMarkup(buttons))
        return

    # ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ ë£¨íŠ¸: ë‰´ìŠ¤ ì¢…ëª© ì„ íƒ
    if data == "news_root":
        await q.edit_message_reply_markup(reply_markup=build_news_category_menu())
        return

    # ë‰´ìŠ¤ â€“ ì¢…ëª© ì„ íƒ
    if data.startswith("news_cat:"):
        sport = data.split(":", 1)[1]
        await q.edit_message_reply_markup(reply_markup=build_news_list_menu(sport))
        return

    # ë‰´ìŠ¤ ì œëª© í´ë¦­ â†’ ì±„íŒ…ì°½ì— ìš”ì•½ ë©”ì‹œì§€ë¡œ ë³´ë‚´ê¸°
    if data.startswith("news_item:"):
        try:
            _, sport, news_id = data.split(":", 2)
            items = NEWS_DATA.get(sport, [])
            title = "ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
            summary = "í•´ë‹¹ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            for item in items:
                if item["id"] == news_id:
                    title = item["title"]
                    summary = item["summary"]
                    break
        except Exception:
            title = "ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
            summary = "í•´ë‹¹ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        text = f"ğŸ“° ë‰´ìŠ¤ ìš”ì•½ â€“ {title}\n\n{summary}"

        buttons = [
            [InlineKeyboardButton("ğŸ“º ìŠ¤í¬ì¸ ë¬´ë£Œì¤‘ê³„", url="https://goat-tv.com")],
            [InlineKeyboardButton("ğŸ“° ë‹¤ë¥¸ ë‰´ìŠ¤ ë³´ê¸°", callback_data="news_root")],
            [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
        ]

        await q.message.reply_text(
            text,
            reply_markup=InlineKeyboardMarkup(buttons),
        )
        return


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹¤í–‰ë¶€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    # ì„œë²„ ì‹œì‘í•  ë•Œ í•œ ë²ˆ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì½ì–´ì˜¤ê¸°
    reload_analysis_from_sheet()
    reload_news_from_sheet()

    app = ApplicationBuilder().token(TOKEN).build()

    # 1:1 í…ŒìŠ¤íŠ¸ìš©
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("myid", myid))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    # ì±„ë„ ë©”ë‰´ìš©
    app.add_handler(CommandHandler("publish", publish))

    # êµ¬ê¸€ì‹œíŠ¸ ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨
    app.add_handler(CommandHandler("syncsheet", syncsheet))

    # ğŸ”¹ ì˜¤ëŠ˜ â† ë‚´ì¼ ë³µì‚¬ìš© ë¡¤ì˜¤ë²„ ëª…ë ¹
    app.add_handler(CommandHandler("rollover", rollover))

    # ğŸ”¹ í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ í¬ë¡¤ë§ ëª…ë ¹
    app.add_handler(CommandHandler("crawlsoccer", crawlsoccer))

    app.add_handler(CallbackQueryHandler(on_callback))

    port = int(os.environ.get("PORT", "10000"))
    app.run_webhook(
        listen="0.0.0.0",
        port=port,
        url_path=TOKEN,
        webhook_url=f"{APP_URL}/{TOKEN}",
    )


if __name__ == "__main__":
    main()

