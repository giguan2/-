import os
import json
import time
import re
import requests
import httpx
from bs4 import BeautifulSoup
from urllib.parse import urljoin

from telegram import (
    Update,
    ReplyKeyboardMarkup,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
)

from datetime import datetime, timedelta

from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

import gspread
from oauth2client.service_account import ServiceAccountCredentials

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOKEN = os.getenv("BOT_TOKEN")
APP_URL = (os.getenv("APP_URL") or "").strip()
CHANNEL_ID = (os.getenv("CHANNEL_ID") or "").strip()  # ì˜ˆ: @ì±„ë„ì•„ì´ë”” ë˜ëŠ” -100xxxxxxxxxxxx

# ğŸ”´ ì—¬ê¸°ë§Œ ë„¤ ë´‡ ìœ ì €ë„¤ì„ìœ¼ë¡œ ìˆ˜ì •í•˜ë©´ ë¨ (@ ë¹¼ê³ )
BOT_USERNAME = "castlive_bot"  # ì˜ˆ: @castlive_bot ì´ë¼ë©´ "castlive_bot"

# ğŸ”¹ ê´€ë¦¬ì ID ëª©ë¡ (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ëª… ê°€ëŠ¥) ì˜ˆ: "123456789,987654321"
_admin_ids_raw = os.getenv("ADMIN_IDS", "")
ADMIN_IDS = [
    int(x.strip())
    for x in _admin_ids_raw.split(",")
    if x.strip().isdigit()
]

def is_admin(update: Update) -> bool:
    """ì´ ëª…ë ¹ì–´ë¥¼ ëˆ„ê°€ í˜¸ì¶œí–ˆëŠ”ì§€ í™•ì¸í•´ì„œ, ê´€ë¦¬ìë©´ True ë¦¬í„´"""
    if not ADMIN_IDS:
        # ADMIN_IDSë¥¼ ì•ˆ ë„£ì—ˆìœ¼ë©´ ê·¸ëƒ¥ ëª¨ë‘ í—ˆìš© (í…ŒìŠ¤íŠ¸ìš©)
        return True
    user = update.effective_user
    return bool(user and user.id in ADMIN_IDS)
    
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‚ ì§œ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_kst_now() -> datetime:
    """í•œêµ­ ì‹œê°„ ê¸°ì¤€ í˜„ì¬ ì‹œê° (UTC+9)"""
    return datetime.utcnow() + timedelta(hours=9)


def get_date_labels():
    """
    ì˜¤ëŠ˜ / ë‚´ì¼ ë‚ ì§œë¥¼ 'M.DD' í˜•ì‹ìœ¼ë¡œ ëŒë ¤ì¤Œ
    ì˜ˆ: ( '11.14', '11.15' )
    """
    now_kst = get_kst_now().date()
    today = now_kst
    tomorrow = now_kst + timedelta(days=1)

    today_str = f"{today.month}.{today.day:02d}"
    tomorrow_str = f"{tomorrow.month}.{tomorrow.day:02d}"
    return today_str, tomorrow_str


def get_menu_caption() -> str:
    """ë©”ì¸ ë©”ë‰´ ì„¤ëª… í…ìŠ¤íŠ¸ (ì˜¤ëŠ˜/ë‚´ì¼ ë‚ ì§œ ìë™ ë°˜ì˜)"""
    today_str, tomorrow_str = get_date_labels()
    return (
        "ğŸ“Œ ìŠ¤í¬ì¸  ì •ë³´&ë¶„ì„ ê³µìœ ë°© ë©”ë‰´ ì•ˆë‚´\n\n"
        "1ï¸âƒ£ ì‹¤ì‹œê°„ ë¬´ë£Œ ì¤‘ê³„ - GOAT-TV ë¼ì´ë¸Œ ì¤‘ê³„ ë°”ë¡œê°€ê¸°\n"
        f"2ï¸âƒ£ {today_str} ê²½ê¸° ë¶„ì„í”½ - ì¢…ëª©ë³„ë¡œ {today_str} ê²½ê¸° ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”\n"
        f"3ï¸âƒ£ {tomorrow_str} ê²½ê¸° ë¶„ì„í”½ - ì¢…ëª©ë³„ë¡œ {tomorrow_str} ê²½ê¸° ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”\n"
        "4ï¸âƒ£ ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ - ì£¼ìš” ì´ìŠˆ & ë‰´ìŠ¤ ìš”ì•½ ì •ë¦¬\n\n"
        "ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì›í•˜ëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡"
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¶„ì„/ë‰´ìŠ¤ ë°ì´í„° (ì˜ˆì‹œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ANALYSIS_TODAY = {
    "ì¶•êµ¬": [
            ],
    "ë†êµ¬": [
         ],
    "ì•¼êµ¬": [
      ],
    "ë°°êµ¬": [
    ],
}
ANALYSIS_TOMORROW = {
    "ì¶•êµ¬": [
    ],
    "ë†êµ¬": [
    ],
    "ì•¼êµ¬": [
    ],
    "ë°°êµ¬": [
    ],
}

ANALYSIS_DATA_MAP = {
    "today": ANALYSIS_TODAY,
    "tomorrow": ANALYSIS_TOMORROW,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# GOOGLE_SERVICE_KEY  : ì„œë¹„ìŠ¤ê³„ì • JSON ì „ì²´ (Render í™˜ê²½ë³€ìˆ˜)
# SPREADSHEET_ID      : êµ¬ê¸€ì‹œíŠ¸ ID (í™˜ê²½ë³€ìˆ˜)
# SHEET_TODAY_NAME    : ì˜¤ëŠ˜ íƒ­ ì´ë¦„ (ê¸°ë³¸ê°’ "today")
# SHEET_TOMORROW_NAME : ë‚´ì¼ íƒ­ ì´ë¦„ (ê¸°ë³¸ê°’ "tomorrow")

_gs_client = None  # gspread í´ë¼ì´ì–¸íŠ¸ ìºì‹œìš©


def get_gs_client():
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„œë¹„ìŠ¤ê³„ì • JSON ì½ì–´ì„œ gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    global _gs_client
    if _gs_client is not None:
        return _gs_client

    key_raw = os.getenv("GOOGLE_SERVICE_KEY")
    if not key_raw:
        print("[GSHEET] GOOGLE_SERVICE_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸ ì—°ë™ ê±´ë„ˆëœ€.")
        return None

    try:
        key_data = json.loads(key_raw)
    except Exception as e:
        print(f"[GSHEET] GOOGLE_SERVICE_KEY JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

    scope = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]

    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_data, scope)
    _gs_client = gspread.authorize(creds)
    print("[GSHEET] gspread ì¸ì¦ ì™„ë£Œ")
    return _gs_client

def summarize_text(text: str, max_len: int = 400) -> str:
    """
    ì•„ì£¼ ë‹¨ìˆœí•œ ìš”ì•½: ë¬¸ì¥ì„ ì˜ë¼ì„œ ì•ì—ì„œë¶€í„° max_lenê¹Œì§€ ìë¥´ëŠ” ë°©ì‹.
    """
    text = text.replace("\n", " ").strip()
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ëŒ€ì¶© ìë¥´ê¸° (í•œêµ­ì–´ë¼ ëŒ€ì¶© ë§ˆì¹¨í‘œ/ë‹¤/ìš” ê¸°ì¤€)
    sentences = re.split(r'(?<=[\.!?ë‹¤ìš”])\s+', text)
    result = ""
    for s in sentences:
        s = s.strip()
        if not s:
            continue
        if not result:
            candidate = s
        else:
            candidate = result + " " + s
        if len(candidate) > max_len:
            break
        result = candidate
    # ë„ˆë¬´ ì§§ìœ¼ë©´ ê·¸ëƒ¥ ì›ë¬¸ í•œ ë²ˆ ë” ì˜ë¼ì¤Œ
    if not result:
        result = text[:max_len]
    return result

def crawl_naver_soccer(max_count: int = 5) -> list[dict]:
    """
    ë„¤ì´ë²„ í•´ì™¸ì¶•êµ¬ ìµœì‹  ë‰´ìŠ¤ ì¼ë¶€ë¥¼ í¬ë¡¤ë§í•´ì„œ
    [ {title, summary}, ... ] ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    BASE_URL = "https://sports.news.naver.com/wfootball/news/index?isphoto=N"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    articles: list[dict] = []

    try:
        resp = requests.get(BASE_URL, headers=headers, timeout=10)
        resp.raise_for_status()
    except Exception as e:
        print(f"[CRAWLER] ëª©ë¡ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return articles

    soup = BeautifulSoup(resp.text, "html.parser")

    # âš ï¸ ë„¤ì´ë²„ ìŠ¤í¬ì¸  êµ¬ì¡°ê°€ ì¡°ê¸ˆì”© ë°”ë€” ìˆ˜ ìˆì–´ì„œ, ì¼ë‹¨ ëŒ€í‘œì ì¸ selector ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±
    # í•„ìš”í•˜ë©´ ë‚˜ì¤‘ì— selectorë§Œ ìˆ˜ì •í•˜ë©´ ë¨
    link_elems = soup.select("div#_newsList a.title")

    links: list[str] = []
    for a in link_elems:
        href = a.get("href", "")
        if not href:
            continue
        # ìƒëŒ€ ê²½ë¡œë©´ ë¶™ì—¬ì£¼ê¸°
        if href.startswith("/"):
            href = "https://sports.news.naver.com" + href
        links.append(href)
        if len(links) >= max_count:
            break

    for link in links:
        try:
            resp2 = requests.get(link, headers=headers, timeout=10)
            resp2.raise_for_status()
            s2 = BeautifulSoup(resp2.text, "html.parser")

            # ì œëª©
            title_el = s2.select_one("h4.title, h2.news_tit, h2#title_area")
            if not title_el:
                print(f"[CRAWLER] ì œëª© íƒœê·¸ ëª» ì°¾ìŒ: {link}")
                continue
            title = title_el.get_text(strip=True)

            # ë³¸ë¬¸
            body_el = (
                s2.select_one("div#newsEndContents")
                or s2.select_one("div.news_end")
                or s2.select_one("div#newsEndBody")
            )
            if not body_el:
                print(f"[CRAWLER] ë³¸ë¬¸ íƒœê·¸ ëª» ì°¾ìŒ: {link}")
                continue

            body_text = body_el.get_text(" ", strip=True)
            summary = summarize_text(body_text, max_len=400)

            articles.append(
                {
                    "title": title,
                    "summary": summary,
                    "url": link,
                }
            )
        except Exception as e:
            print(f"[CRAWLER] ê¸°ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ({link}): {e}")
            continue

    return articles

def _load_analysis_sheet(sh, sheet_name: str) -> dict:
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ í•œ íƒ­(today / tomorrow)ì„ ì½ì–´ì„œ
    { sport: [ {id,title,summary}, ... ] } êµ¬ì¡°ë¡œ ë³€í™˜

    ì‹œíŠ¸ ì»¬ëŸ¼ êµ¬ì¡° (1í–‰ í—¤ë” ê¸°ì¤€):
    Aì—´: sport   (ì˜ˆ: ì¶•êµ¬/ë†êµ¬/ì•¼êµ¬/ë°°êµ¬)
    Bì—´: id      (botì—ì„œ ì“¸ ê³ ìœ  id, ë¹„ì›Œë‘ë©´ ìë™ ìƒì„±)
    Cì—´: title   (ë²„íŠ¼ì— ë³´ì´ëŠ” ì œëª©)
    Dì—´: summary (ë¶„ì„ ë³¸ë¬¸)
    """
    try:
        ws = sh.worksheet(sheet_name)
    except Exception as e:
        print(f"[GSHEET] ì‹œíŠ¸ '{sheet_name}' ì—´ê¸° ì‹¤íŒ¨: {e}")
        return {}

    rows = ws.get_all_values()
    if not rows:
        return {}

    # í—¤ë” íŒŒì‹± (ì²« í–‰)
    header = rows[0]
    # ê¸°ë³¸ ì¸ë±ìŠ¤
    idx_sport = 0
    idx_id = 1
    idx_title = 2
    idx_summary = 3

    def safe_index(name, default):
        try:
            return header.index(name)
        except ValueError:
            return default

    # í—¤ë”ì— 'sport', 'id', 'title', 'summary' ê¸€ìê°€ ìˆìœ¼ë©´ ê·¸ ìœ„ì¹˜ ì‚¬ìš©
    idx_sport = safe_index("sport", idx_sport)
    idx_id = safe_index("id", idx_id)
    idx_title = safe_index("title", idx_title)
    idx_summary = safe_index("summary", idx_summary)

    data: dict[str, list[dict]] = {}

    for row in rows[1:]:  # ë°ì´í„° í–‰
        if len(row) <= idx_title:
            continue

        sport = (row[idx_sport] if len(row) > idx_sport else "").strip()
        if not sport:
            continue

        item_id = (row[idx_id] if len(row) > idx_id else "").strip()
        title = (row[idx_title] if len(row) > idx_title else "").strip()
        summary = (row[idx_summary] if len(row) > idx_summary else "").strip()

        if not title:
            continue

        # id ì—†ìœ¼ë©´ ìë™ ìƒì„±
        if not item_id:
            cur_len = len(data.get(sport, []))
            item_id = f"{sport}_{cur_len + 1}"

        entry = {
            "id": item_id,
            "title": title,
            "summary": summary,
        }
        data.setdefault(sport, []).append(entry)

    return data


def reload_analysis_from_sheet():
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ today / tomorrow íƒ­ì„ ì½ì–´ì„œ
    ANALYSIS_TODAY / ANALYSIS_TOMORROW / ANALYSIS_DATA_MAP ê°±ì‹ 
    """
    global ANALYSIS_TODAY, ANALYSIS_TOMORROW, ANALYSIS_DATA_MAP

    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not client or not spreadsheet_id:
        print("[GSHEET] ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” SPREADSHEET_ID ì—†ìŒ â†’ ê¸°ì¡´ í•˜ë“œì½”ë”© ë°ì´í„° ì‚¬ìš©")
        return

    try:
        sh = client.open_by_key(spreadsheet_id)
    except Exception as e:
        print(f"[GSHEET] ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° ì‹¤íŒ¨: {e}")
        return

    sheet_today_name = os.getenv("SHEET_TODAY_NAME", "today")
    sheet_tomorrow_name = os.getenv("SHEET_TOMORROW_NAME", "tomorrow")

    print(f"[GSHEET] '{sheet_today_name}' / '{sheet_tomorrow_name}' íƒ­ì—ì„œ ë¶„ì„ ë°ì´í„° ë¡œë”© ì‹œë„")

    try:
        today_data = _load_analysis_sheet(sh, sheet_today_name)
        tomorrow_data = _load_analysis_sheet(sh, sheet_tomorrow_name)
    except Exception as e:
        print(f"[GSHEET] ì‹œíŠ¸ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return

    # ì‹œíŠ¸ì—ì„œ ì½ì–´ì˜¨ ë‚´ìš©ì´ ë¹„ì–´ ìˆì–´ë„ ê·¸ëŒ€ë¡œ ë°˜ì˜
    # (today / tomorrow íƒ­ì´ í—¤ë”ë§Œ ìˆì–´ë„, ë‚´ì¼ ë²„íŠ¼ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì•ˆ ëœ¨ê²Œ)
    ANALYSIS_TODAY = today_data
    ANALYSIS_TOMORROW = tomorrow_data

    ANALYSIS_DATA_MAP = {
        "today": ANALYSIS_TODAY,
        "tomorrow": ANALYSIS_TOMORROW,
    }

    print("[GSHEET] ANALYSIS_TODAY / ANALYSIS_TOMORROW ê°±ì‹  ì™„ë£Œ")
    
NEWS_DATA = {}

def _load_news_sheet(sh, sheet_name: str) -> dict:
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë‰´ìŠ¤ íƒ­ì„ ì½ì–´ì„œ
    {
        sport: [ {id,title,summary}, ... ]
    } êµ¬ì¡°ë¡œ ë³€í™˜

    ì‹œíŠ¸ ì»¬ëŸ¼ êµ¬ì¡° (1í–‰ í—¤ë” ê¸°ì¤€):
    Aì—´: sport
    Bì—´: id
    Cì—´: title
    Dì—´: summary
    """
    try:
        ws = sh.worksheet(sheet_name)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ì‹œíŠ¸ '{sheet_name}' ì—´ê¸° ì‹¤íŒ¨: {e}")
        return {}

    rows = ws.get_all_values()
    if not rows:
        return {}

    header = rows[0]

    # ê¸°ë³¸ index
    idx_sport = 0
    idx_id = 1
    idx_title = 2
    idx_summary = 3

    # í—¤ë” ê¸°ë°˜ ë™ì  ë§¤ì¹­
    def safe_index(name, default):
        try:
            return header.index(name)
        except ValueError:
            return default

    idx_sport = safe_index("sport", idx_sport)
    idx_id = safe_index("id", idx_id)
    idx_title = safe_index("title", idx_title)
    idx_summary = safe_index("summary", idx_summary)

    data: dict[str, list[dict]] = {}

    for row in rows[1:]:
        if len(row) <= idx_title:
            continue

        sport = (row[idx_sport] if len(row) > idx_sport else "").strip()
        if not sport:
            continue

        item_id = (row[idx_id] if len(row) > idx_id else "").strip()
        title = (row[idx_title] if len(row) > idx_title else "").strip()
        summary = (row[idx_summary] if len(row) > idx_summary else "").strip()

        if not title:
            continue

        # id ë¹„ì–´ ìˆìœ¼ë©´ ìë™ ìƒì„±
        if not item_id:
            cur_len = len(data.get(sport, []))
            item_id = f"{sport}_news_{cur_len + 1}"

        entry = {
            "id": item_id,
            "title": title,
            "summary": summary,
        }
        data.setdefault(sport, []).append(entry)

    return data

def reload_news_from_sheet():
    """êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë‰´ìŠ¤ íƒ­ì„ ì½ì–´ì„œ NEWS_DATA ê°±ì‹ """
    global NEWS_DATA
    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not client or not spreadsheet_id:
        print("[GSHEET] ë‰´ìŠ¤ìš© SPREADSHEET ì—°ë™ ì‹¤íŒ¨ â†’ ê¸°ì¡´ í•˜ë“œì½”ë”© NEWS_DATA ì‚¬ìš©.")
        return

    try:
        sh = client.open_by_key(spreadsheet_id)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° ì‹¤íŒ¨: {e}")
        return

    sheet_news_name = os.getenv("SHEET_NEWS_NAME", "news")
    print(f"[GSHEET] '{sheet_news_name}' íƒ­ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì‹œë„")

    try:
        news_data = _load_news_sheet(sh, sheet_news_name)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ì‹œíŠ¸ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return

    NEWS_DATA = news_data
    print("[GSHEET] NEWS_DATA ê°±ì‹  ì™„ë£Œ")



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‚¤ë³´ë“œ/ë©”ë‰´ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_reply_keyboard() -> ReplyKeyboardMarkup:
    """ë´‡ 1:1 í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨ í•˜ë‹¨ í‚¤ë³´ë“œ"""
    menu = [
        ["ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°", "ë„ì›€ë§"],
    ]
    return ReplyKeyboardMarkup(menu, resize_keyboard=True)


def build_main_inline_menu() -> InlineKeyboardMarkup:
    """
    ë©”ì¸ ì¸ë¼ì¸ ë©”ë‰´ (ì±„ë„/ë¯¸ë¦¬ë³´ê¸° ê³µí†µ)
    ì±„ë„ì—ì„œëŠ” ì´ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê°ì ë´‡ DMìœ¼ë¡œ ì´ë™í•˜ê²Œ í•¨.
    """
    today_str, tomorrow_str = get_date_labels()

    buttons = [
        [InlineKeyboardButton("ì‹¤ì‹œê°„ ë¬´ë£Œ ì¤‘ê³„", url="https://goat-tv.com")],
        [
            InlineKeyboardButton(
                f"{today_str} ê²½ê¸° ë¶„ì„í”½",
                url=f"https://t.me/{BOT_USERNAME}?start=today",
            )
        ],
        [
            InlineKeyboardButton(
                f"{tomorrow_str} ê²½ê¸° ë¶„ì„í”½",
                url=f"https://t.me/{BOT_USERNAME}?start=tomorrow",
            )
        ],
        [
            InlineKeyboardButton(
                "ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½",
                url=f"https://t.me/{BOT_USERNAME}?start=news",
            )
        ],
    ]
    return InlineKeyboardMarkup(buttons)


def build_analysis_category_menu(key: str) -> InlineKeyboardMarkup:
    # key = "today" or "tomorrow"
    buttons = [
        [InlineKeyboardButton("âš½ï¸ì¶•êµ¬âš½ï¸", callback_data=f"analysis_cat:{key}:ì¶•êµ¬")],
        [InlineKeyboardButton("ğŸ€ë†êµ¬ğŸ€", callback_data=f"analysis_cat:{key}:ë†êµ¬")],
        [InlineKeyboardButton("âš¾ï¸ì•¼êµ¬âš¾ï¸", callback_data=f"analysis_cat:{key}:ì•¼êµ¬")],
        [InlineKeyboardButton("ğŸë°°êµ¬ğŸ", callback_data=f"analysis_cat:{key}:ë°°êµ¬")],
        [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
    ]
    return InlineKeyboardMarkup(buttons)



def build_analysis_match_menu(key: str, sport: str) -> InlineKeyboardMarkup:
    """ì¢…ëª© ì„ íƒ í›„ â†’ í•´ë‹¹ ì¢…ëª© ê²½ê¸° ë¦¬ìŠ¤íŠ¸ ë©”ë‰´"""
    items = ANALYSIS_DATA_MAP.get(key, {}).get(sport, [])
    buttons = []
    for item in items:
        cb = f"match:{key}:{sport}:{item['id']}"
        buttons.append([InlineKeyboardButton(item["title"], callback_data=cb)])

    buttons.append([InlineKeyboardButton("â—€ ì¢…ëª© ì„ íƒìœ¼ë¡œ", callback_data=f"analysis_root:{key}")])
    buttons.append([InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")])
    return InlineKeyboardMarkup(buttons)


def build_news_category_menu() -> InlineKeyboardMarkup:
    """ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ â†’ ì¢…ëª© ì„ íƒ ë©”ë‰´"""
    buttons = [
        [InlineKeyboardButton("âš½ï¸ì¶•êµ¬ ë‰´ìŠ¤âš½ï¸", callback_data="news_cat:ì¶•êµ¬")],
        [InlineKeyboardButton("ğŸ€ë†êµ¬ ë‰´ìŠ¤ğŸ€", callback_data="news_cat:ë†êµ¬")],
        [InlineKeyboardButton("âš¾ï¸ì•¼êµ¬ ë‰´ìŠ¤âš¾ï¸", callback_data="news_cat:ì•¼êµ¬")],
        [InlineKeyboardButton("ğŸë°°êµ¬ ë‰´ìŠ¤ğŸ", callback_data="news_cat:ë°°êµ¬")],
        [InlineKeyboardButton("ê¸°íƒ€ì¢…ëª© ë‰´ìŠ¤", callback_data="news_cat:ê¸°íƒ€ì¢…")],
        [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
    ]
    return InlineKeyboardMarkup(buttons)


def build_news_list_menu(sport: str) -> InlineKeyboardMarkup:
    """ì¢…ëª© ì„ íƒ í›„ â†’ í•´ë‹¹ ì¢…ëª© ë‰´ìŠ¤ ì œëª© ë¦¬ìŠ¤íŠ¸ ë©”ë‰´"""
    items = NEWS_DATA.get(sport, [])
    buttons = []
    for item in items:
        cb = f"news_item:{sport}:{item['id']}"
        buttons.append([InlineKeyboardButton(item["title"], callback_data=cb)])

    buttons.append([InlineKeyboardButton("â—€ ì¢…ëª© ì„ íƒìœ¼ë¡œ", callback_data="news_root")])
    buttons.append([InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")])
    return InlineKeyboardMarkup(buttons)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ: ë©”ì¸ ë©”ë‰´ ë³´ë‚´ëŠ” í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def send_main_menu(chat_id: int | str, context: ContextTypes.DEFAULT_TYPE, preview: bool = False):
    """
    ì±„ë„/DM ê³µí†µìœ¼ë¡œ 'í…ìŠ¤íŠ¸ + ë©”ì¸ ë©”ë‰´ ë²„íŠ¼' ì „ì†¡.
    """
    msg = await context.bot.send_message(
        chat_id=chat_id,
        text=get_menu_caption(),
        reply_markup=build_main_inline_menu(),
    )
    return msg

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•¸ë“¤ëŸ¬ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1) /start â€“ DMì—ì„œ ì±„ë„ê³¼ ë™ì¼í•œ ë ˆì´ì•„ì›ƒ or ë°”ë¡œ ë©”ë‰´ ì§„ì…
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    args = context.args
    mode = args[0] if args else None

    today_str, tomorrow_str = get_date_labels()

    # ì˜¤ëŠ˜ ë¶„ì„ ë²„íŠ¼
    if mode == "today":
        await update.message.reply_text(
            f"{today_str} ê²½ê¸° ë¶„ì„í”½ ë©”ë‰´ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_analysis_category_menu("today"),
        )
        return

    # ë‚´ì¼ ë¶„ì„ ë²„íŠ¼
    if mode == "tomorrow":
        await update.message.reply_text(
            f"{tomorrow_str} ê²½ê¸° ë¶„ì„í”½ ë©”ë‰´ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_analysis_category_menu("tomorrow"),
        )
        return

    if mode == "news":
        await update.message.reply_text(
            "ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_news_category_menu(),
        )
        return

    # ê·¸ ì™¸: DMì—ì„œ ì „ì²´ ë ˆì´ì•„ì›ƒ ë¯¸ë¦¬ë³´ê¸°
    await update.message.reply_text(
        "ìŠ¤í¬ì¸ ë´‡ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ì—ëŠ” ì±„ë„ì— ì˜¬ë¼ê°ˆ ë©”ë‰´ì™€ ë™ì¼í•œ ë ˆì´ì•„ì›ƒ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë³´ì—¬ì¤„ê²Œ.\n"
        "ì‹¤ì œ ì±„ë„ ë°°í¬ëŠ” /publish ëª…ë ¹ìœ¼ë¡œ ì§„í–‰í•˜ë©´ ë¼.",
        reply_markup=build_reply_keyboard(),
    )

    await send_main_menu(chat_id, context, preview=True)

async def myid(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    await update.message.reply_text(f"ë‹¹ì‹ ì˜ í…”ë ˆê·¸ë¨ ID: {uid}")

# 2) DM í…ìŠ¤íŠ¸ ì²˜ë¦¬ â€“ ê°„ë‹¨ í…ŒìŠ¤íŠ¸ìš©
async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    if "ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°" in text:
        await start(update, context)
    elif "ë„ì›€ë§" in text:
        await update.message.reply_text(
            "/start : ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°\n"
            "/publish : ì±„ë„ì— ë©”ë‰´ ì „ì†¡ + ìƒë‹¨ ê³ ì •"
        )
    else:
        await update.message.reply_text("ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°ëŠ” /start ë˜ëŠ” 'ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")


# 3) /publish â€“ ì±„ë„ë¡œ ë©”ë‰´ ë³´ë‚´ê³  ìƒë‹¨ ê³ ì •
# 3) /publish â€“ ì±„ë„ë¡œ ë©”ë‰´ ë³´ë‚´ê³  ìƒë‹¨ ê³ ì •
async def publish(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    
    if not CHANNEL_ID:
        await update.message.reply_text("CHANNEL_IDê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. Render í™˜ê²½ë³€ìˆ˜ì— CHANNEL_IDë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return

    # ê¸°ì¡´ ê³ ì • ë©”ì‹œì§€ í•´ì œ (ì„ íƒ)
    try:
        await context.bot.unpin_all_chat_messages(CHANNEL_ID)
    except Exception:
        pass

    # ì±„ë„ì— DMê³¼ ë™ì¼í•œ ë©”ë‰´ ì „ì†¡
    msg = await send_main_menu(CHANNEL_ID, context, preview=False)

    # ë°©ê¸ˆ ë³´ë‚¸ ë©”ë‰´ ë©”ì‹œì§€ ìƒë‹¨ ê³ ì •
    await context.bot.pin_chat_message(
        chat_id=CHANNEL_ID,
        message_id=msg.message_id,
        disable_notification=True,
    )

    await update.message.reply_text("ì±„ë„ì— ë©”ë‰´ë¥¼ ì˜¬ë¦¬ê³  ìƒë‹¨ì— ê³ ì •í–ˆìŠµë‹ˆë‹¤ âœ…")

# 5) /syncsheet â€“ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë¶„ì„ ë°ì´í„° ë‹¤ì‹œ ë¡œë”©
async def syncsheet(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
        
    try:
        reload_analysis_from_sheet()
        reload_news_from_sheet()         
        await update.message.reply_text("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë¶„ì„ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤ âœ…")
    except Exception as e:
        await update.message.reply_text(f"êµ¬ê¸€ì‹œíŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ğŸ”¹ 4) /rollover â€“ ë‚´ì¼ ë¶„ì„ â†’ ì˜¤ëŠ˜ ë¶„ì„ìœ¼ë¡œ ë³µì‚¬
async def rollover(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
        
    # 1) êµ¬ê¸€ì‹œíŠ¸ today â† tomorrow ë¡¤ì˜¤ë²„
    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if client and spreadsheet_id:
        try:
            sh = client.open_by_key(spreadsheet_id)

            sheet_today_name = os.getenv("SHEET_TODAY_NAME", "today")
            sheet_tomorrow_name = os.getenv("SHEET_TOMORROW_NAME", "tomorrow")

            ws_today = sh.worksheet(sheet_today_name)
            ws_tomorrow = sh.worksheet(sheet_tomorrow_name)

            # tomorrow íƒ­ ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            rows = ws_tomorrow.get_all_values()

            if rows:
                # 1-1) today íƒ­ì„ tomorrow ë‚´ìš©ìœ¼ë¡œ í†µì§¸ë¡œ ë®ì–´ì“°ê¸°
                ws_today.clear()
                ws_today.update("A1", rows)

                # 1-2) tomorrow íƒ­ì€ í—¤ë”ë§Œ ë‚¨ê¸°ê³  ë¹„ìš°ê¸°
                header = rows[0]
                ws_tomorrow.clear()
                ws_tomorrow.update("A1", [header])
            else:
                print("[GSHEET] tomorrow íƒ­ì— ë°ì´í„°ê°€ ì—†ì–´ ì‹œíŠ¸ ë¡¤ì˜¤ë²„ëŠ” ìƒëµí•©ë‹ˆë‹¤.")

        except Exception as e:
            print(f"[GSHEET] ë¡¤ì˜¤ë²„ ì¤‘ ì‹œíŠ¸ ë³µì‚¬ ì‹¤íŒ¨: {e}")

    else:
        print("[GSHEET] í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” SPREADSHEET_ID ì—†ìŒ â†’ ì‹œíŠ¸ ë¡¤ì˜¤ë²„ëŠ” ê±´ë„ˆëœ€.")

    # 2) ë©”ëª¨ë¦¬(ANALYSIS_TODAY / ANALYSIS_TOMORROW)ë„ ì‹œíŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ë¡œë”©
    reload_analysis_from_sheet()

    # 3) ì•ˆë‚´ ë©”ì‹œì§€
    await update.message.reply_text(
        "âœ… ë¡¤ì˜¤ë²„ ì™„ë£Œ!\n"
        "êµ¬ê¸€ì‹œíŠ¸ 'tomorrow' íƒ­ ë‚´ìš©ì„ 'today' íƒ­ìœ¼ë¡œ ë³µì‚¬í–ˆê³ ,\n"
        "'tomorrow' íƒ­ì€ í—¤ë”ë§Œ ë‚¨ê¸°ê³  ì´ˆê¸°í™”í–ˆì–´.\n\n"
        "ì´ì œ ì˜¤ëŠ˜ ê²½ê¸° ë¶„ì„ì€ 'today' íƒ­ì—ì„œ, ë‚´ì¼ ê²½ê¸°ëŠ” 'tomorrow' íƒ­ì—ì„œ ì‘ì„±í•˜ë©´ ë¼."
    )

def simple_summarize(text: str, max_chars: int = 400) -> str:
    """
    ì•„ì£¼ ë‹¨ìˆœ ìš”ì•½: ë¬¸ì¥ ì‚¬ì´ ê³µë°± ì •ë¦¬ í›„,
    max_chars ì•ˆìª½ì—ì„œ 'ë‹¤.' ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ì„œ ë°˜í™˜.
    """
    if not text:
        return ""

    # ê³µë°± ì •ë¦¬
    text = re.sub(r"\s+", " ", text).strip()

    if len(text) <= max_chars:
        return text

    # 'ë‹¤.' ê¸°ì¤€ìœ¼ë¡œ ì ë‹¹íˆ ëŠê¸°
    cut = text.rfind("ë‹¤.", 0, max_chars)
    if cut != -1:
        return text[: cut + 2]

    return text[:max_chars] + "..."


async def fetch_article_body(client: httpx.AsyncClient, url: str) -> str:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ.
    (ëª¨ë°”ì¼/PC ë‘˜ ë‹¤ ì‹œë„)
    """
    try:
        r = await client.get(url, timeout=10.0, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
    except Exception as e:
        print(f"[CRAWL][ARTICLE] ìš”ì²­ ì‹¤íŒ¨: {url} / {e}")
        return ""

    soup = BeautifulSoup(r.text, "html.parser")

    # 1) ëª¨ë°”ì¼ ìŠ¤í¬ì¸  ë‰´ìŠ¤ (m.sports.naver.com) ìª½ êµ¬ì¡°
    body = soup.select_one("#newsEndContents")
    if body:
        return body.get_text("\n", strip=True)

    # 2) PC ìŠ¤í¬ì¸  ë‰´ìŠ¤ (sports.news.naver.com) ìª½ êµ¬ì¡°
    body = soup.select_one("#newsEndBody")
    if body:
        return body.get_text("\n", strip=True)

    # 3) ì¼ë°˜ ë„¤ì´ë²„ ë‰´ìŠ¤ êµ¬ì¡° (í˜¹ì‹œ ëª°ë¼ì„œ)
    body = soup.select_one("#dic_area")
    if body:
        return body.get_text("\n", strip=True)

    # ê·¸ë˜ë„ ëª» ì°¾ìœ¼ë©´ ë¡œê·¸ë§Œ ì°ê³  ë¹ˆ ë¬¸ìì—´
    print(f"[CRAWL][ARTICLE] ë³¸ë¬¸ ì…€ë ‰í„° ë§¤ì¹˜ ì‹¤íŒ¨: {url}")
    return ""

async def crawlsoccer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # ê´€ë¦¬ìë§Œ ì‚¬ìš©
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    await update.message.reply_text("ë‹¤ìŒìŠ¤í¬ì¸  í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")

    list_url = "https://sports.daum.net/worldsoccer/news"

    try:
        async with httpx.AsyncClient(
            headers={"User-Agent": "Mozilla/5.0"},
            follow_redirects=True,
        ) as client:
            # 1) ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ìš”ì²­
            resp = await client.get(list_url, timeout=10.0)
            resp.raise_for_status()

            soup = BeautifulSoup(resp.text, "html.parser")
            base = str(resp.url)

            articles = []
            seen = set()

            # â”€â”€ 1ë‹¨ê³„: ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œëª© + ë§í¬ ì¶”ì¶œ â”€â”€
            for a in soup.find_all("a", href=True):
                href = a["href"]
                title = a.get_text(strip=True)

                # ë‹¤ìŒ ë‰´ìŠ¤ëŠ” v.daum.net/v/ ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒë§Œ ê¸°ì‚¬
                if not href:
                    continue

                if "v.daum.net/v/" not in href and not href.startswith("/v/"):
                    continue

                if not title or len(title) < 3:
                    continue

                full_url = urljoin(base, href)

                if full_url in seen:
                    continue
                seen.add(full_url)

                articles.append({"title": title, "link": full_url})

                if len(articles) >= 10:
                    break

            if not articles:
                await update.message.reply_text("í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return

            # â”€â”€ 2ë‹¨ê³„: ê° ê¸°ì‚¬ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ â”€â”€
            for art in articles:
                try:
                    r2 = await client.get(art["link"], timeout=10.0)
                    r2.raise_for_status()
                    s2 = BeautifulSoup(r2.text, "html.parser")

                    # ê¸°ì‚¬ ë³¸ë¬¸
                    body_el = (
                        s2.select_one("div#mArticle")
                        or s2.find("article")
                        or s2.body
                    )

                    if body_el:
                        body_text = body_el.get_text("\n", strip=True)
                    else:
                        body_text = ""

                    art["summary"] = simple_summarize(body_text, max_chars=400)

                except Exception as e:
                    print(f"[CRAWL][DAUM] ê¸°ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ({art['link']}): {e}")
                    art["summary"] = "(ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨)"

    except Exception as e:
        await update.message.reply_text(f"ìš”ì²­ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # â”€â”€ 3) êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ â”€â”€
    client_gs = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not (client_gs and spreadsheet_id):
        await update.message.reply_text(
            "êµ¬ê¸€ì‹œíŠ¸ ì„¤ì •(GOOGLE_SERVICE_KEY ë˜ëŠ” SPREADSHEET_ID)ì´ ì—†ì–´ ì‹œíŠ¸ì— ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )
        return

    try:
        sh = client_gs.open_by_key(spreadsheet_id)
        ws = sh.worksheet(os.getenv("SHEET_NEWS_NAME", "news"))
    except Exception as e:
        await update.message.reply_text(f"ë‰´ìŠ¤ ì‹œíŠ¸ë¥¼ ì—´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        return

    rows_to_append = []
    for art in articles:
        rows_to_append.append([
            "ì¶•êµ¬",
            "",
            art["title"],
            art["summary"],
        ])

    try:
        ws.append_rows(rows_to_append, value_input_option="RAW")
    except Exception as e:
        await update.message.reply_text(f"ì‹œíŠ¸ ì“°ê¸° ì˜¤ë¥˜: {e}")
        return

    await update.message.reply_text(
        f"ë‹¤ìŒìŠ¤í¬ì¸  í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ {len(rows_to_append)}ê±´ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
        "/syncsheet ë¡œ í…”ë ˆê·¸ë¨ ë©”ë‰´ë¥¼ ê°±ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )



# 4) ì¸ë¼ì¸ ë²„íŠ¼ ì½œë°± ì²˜ë¦¬ (ë¶„ì„/ë‰´ìŠ¤ íŒì—…)
async def on_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    data = q.data or ""
    await q.answer()  # ê¸°ë³¸ ë¡œë”©í‘œì‹œ ì œê±°

    # ë©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°€ê¸°
    if data == "back_main":
        await q.edit_message_reply_markup(reply_markup=build_main_inline_menu())
        return

    # ë¶„ì„í”½ ë£¨íŠ¸: ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    if data.startswith("analysis_root:"):
        _, key = data.split(":", 1)          # today / tomorrow
        await q.edit_message_reply_markup(reply_markup=build_analysis_category_menu(key))
        return

    # ë¶„ì„í”½ â€“ ì¢…ëª© ì„ íƒ
    if data.startswith("analysis_cat:"):
        _, key, sport = data.split(":", 2)
        await q.edit_message_reply_markup(reply_markup=build_analysis_match_menu(key, sport))
        return

    # âœ… ë¶„ì„í”½ â€“ ê°œë³„ ê²½ê¸° ì„ íƒ â†’ ì±„íŒ…ì°½ì— ë¶„ì„ê¸€ ë©”ì‹œì§€ë¡œ ë³´ë‚´ê¸°
    # âœ… ë¶„ì„í”½ â€“ ê°œë³„ ê²½ê¸° ì„ íƒ â†’ ì±„íŒ…ì°½ì— ë¶„ì„ê¸€ ë©”ì‹œì§€ë¡œ ë³´ë‚´ê¸°
    if data.startswith("match:"):
        _, key, sport, match_id = data.split(":", 3)
        items = ANALYSIS_DATA_MAP.get(key, {}).get(sport, [])

        title = "ì„ íƒí•œ ê²½ê¸°"
        summary = "í•´ë‹¹ ê²½ê¸° ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        for item in items:
            if item["id"] == match_id:
                title = item["title"]
                summary = item["summary"]
                break

        text = f"ğŸ“Œ ê²½ê¸° ë¶„ì„ â€“ {title}\n\n{summary}"

        buttons = [
            [InlineKeyboardButton("ğŸ“º ìŠ¤í¬ì¸  ë¬´ë£Œ ì¤‘ê³„", url="https://goat-tv.com")],
            [InlineKeyboardButton("ğŸ“ ë¶„ì„ê¸€ ë” ë³´ê¸°", callback_data=f"analysis_root:{key}")],
            [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
        ]

        await q.message.reply_text(text, reply_markup=InlineKeyboardMarkup(buttons))
        return


    # ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ ë£¨íŠ¸: ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
    # ê¸ˆì¼ ìŠ¤í¬ì¸  ì •ë³´ ë£¨íŠ¸: ë‰´ìŠ¤ ì¢…ëª© ì„ íƒ
    if data == "news_root":
        await q.edit_message_reply_markup(reply_markup=build_news_category_menu())
        return

    # ë‰´ìŠ¤ â€“ ì¢…ëª© ì„ íƒ
    if data.startswith("news_cat:"):
        sport = data.split(":", 1)[1]
        await q.edit_message_reply_markup(reply_markup=build_news_list_menu(sport))
        return

    # âœ… ë‰´ìŠ¤ ì œëª© í´ë¦­ â†’ ì±„íŒ…ì°½ì— ìš”ì•½ ë©”ì‹œì§€ë¡œ ë³´ë‚´ê¸°
    if data.startswith("news_item:"):
        try:
            _, sport, news_id = data.split(":", 2)
            items = NEWS_DATA.get(sport, [])
            title = "ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
            summary = "í•´ë‹¹ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            for item in items:
                if item["id"] == news_id:
                    title = item["title"]
                    summary = item["summary"]
                    break
        except Exception:
            title = "ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
            summary = "í•´ë‹¹ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        text = f"ğŸ“° ë‰´ìŠ¤ ìš”ì•½ â€“ {title}\n\n{summary}"

        buttons = [
            [InlineKeyboardButton("ğŸ“º ìŠ¤í¬ì¸ ë¬´ë£Œì¤‘ê³„", url="https://goat-tv.com")],
            [InlineKeyboardButton("ğŸ“° ë‹¤ë¥¸ ë‰´ìŠ¤ ë³´ê¸°", callback_data="news_root")],
            [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
        ]

        await q.message.reply_text(
            text,
            reply_markup=InlineKeyboardMarkup(buttons),
        )
        return




# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹¤í–‰ë¶€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    # ì„œë²„ ì‹œì‘í•  ë•Œ í•œ ë²ˆ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì½ì–´ì˜¤ê¸°
    reload_analysis_from_sheet()
    reload_news_from_sheet()

    app = ApplicationBuilder().token(TOKEN).build()

    # 1:1 í…ŒìŠ¤íŠ¸ìš©
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("myid", myid))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    # ì±„ë„ ë©”ë‰´ìš©
    app.add_handler(CommandHandler("publish", publish))

    # êµ¬ê¸€ì‹œíŠ¸ ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨
    app.add_handler(CommandHandler("syncsheet", syncsheet))    
    
    # ğŸ”¹ ì˜¤ëŠ˜ â† ë‚´ì¼ ë³µì‚¬ìš© ë¡¤ì˜¤ë²„ ëª…ë ¹
    app.add_handler(CommandHandler("rollover", rollover))

    # ğŸ”¹ í•´ì™¸ì¶•êµ¬ ë‰´ìŠ¤ í¬ë¡¤ë§ ëª…ë ¹
    app.add_handler(CommandHandler("crawlsoccer", crawlsoccer))    
    
    app.add_handler(CallbackQueryHandler(on_callback))

    port = int(os.environ.get("PORT", "10000"))
    app.run_webhook(
        listen="0.0.0.0",
        port=port,
        url_path=TOKEN,
        webhook_url=f"{APP_URL}/{TOKEN}",
    )


if __name__ == "__main__":
    main()



































