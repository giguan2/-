import os
import json
import time
import re
import requests
import httpx
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from openai import OpenAI

from telegram import (
    Update,
    ReplyKeyboardMarkup,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
)

from datetime import datetime, timedelta, date

from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

import gspread
from oauth2client.service_account import ServiceAccountCredentials

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOKEN = os.getenv("BOT_TOKEN")
APP_URL = (os.getenv("APP_URL") or "").strip()
CHANNEL_ID = (os.getenv("CHANNEL_ID") or "").strip()  # ì˜ˆ: @ì±„ë„ì•„ì´ë”” ë˜ëŠ” -100xxxxxxxxxxxx

# ğŸ”´ ì—¬ê¸°ë§Œ ë„¤ ë´‡ ìœ ì €ë„¤ì„ìœ¼ë¡œ ìˆ˜ì •í•˜ë©´ ë¨ (@ ë¹¼ê³ )
BOT_USERNAME = "castlive_bot"  # ì˜ˆ: @castlive_bot ì´ë¼ë©´ "castlive_bot"

# ğŸ”¹ Gemini API í‚¤ (í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()

# ğŸ”¹ ê´€ë¦¬ì ID ëª©ë¡ (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ëª… ê°€ëŠ¥) ì˜ˆ: "123456789,987654321"
_admin_ids_raw = os.getenv("ADMIN_IDS", "")
ADMIN_IDS = [
    int(x.strip())
    for x in _admin_ids_raw.split(",")
    if x.strip().isdigit()
]


def is_admin(update: Update) -> bool:
    """ì´ ëª…ë ¹ì–´ë¥¼ ëˆ„ê°€ í˜¸ì¶œí–ˆëŠ”ì§€ í™•ì¸í•´ì„œ, ê´€ë¦¬ìë©´ True ë¦¬í„´"""
    if not ADMIN_IDS:
        # ADMIN_IDSë¥¼ ì•ˆ ë„£ì—ˆìœ¼ë©´ ê·¸ëƒ¥ ëª¨ë‘ í—ˆìš© (í…ŒìŠ¤íŠ¸ìš©)
        return True
    user = update.effective_user
    return bool(user and user.id in ADMIN_IDS)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‚ ì§œ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_kst_now() -> datetime:
    """í•œêµ­ ì‹œê°„ ê¸°ì¤€ í˜„ì¬ ì‹œê° (UTC+9)"""
    return datetime.utcnow() + timedelta(hours=9)


def get_date_labels():
    """
    ì˜¤ëŠ˜ / ë‚´ì¼ ë‚ ì§œë¥¼ 'M.DD' í˜•ì‹ìœ¼ë¡œ ëŒë ¤ì¤Œ
    ì˜ˆ: ( '11.14', '11.15' )
    """
    now_kst = get_kst_now().date()
    today = now_kst
    tomorrow = now_kst + timedelta(days=1)

    today_str = f"{today.month}.{today.day:02d}"
    tomorrow_str = f"{tomorrow.month}.{tomorrow.day:02d}"
    return today_str, tomorrow_str

def get_tomorrow_mmdd_str() -> str:
    """
    mazgtv í…Œì´ë¸”ì˜ '11-28 (ê¸ˆ) 02:45' ê°™ì€ ë‚ ì§œì—ì„œ
    ì•ë¶€ë¶„ 'MM-DD' ì™€ ë¹„êµí•˜ê¸° ìœ„í•œ ë‚´ì¼ ë‚ ì§œ ë¬¸ìì—´ ìƒì„± (ì˜ˆ: '11-28')
    """
    tomorrow = get_kst_now().date() + timedelta(days=1)
    return f"{tomorrow.month:02d}-{tomorrow.day:02d}"

def get_tomorrow_keywords():
    """
    í•´ì™¸ë¶„ì„ ë¦¬ìŠ¤íŠ¸ì—ì„œ 'ë‚´ì¼ ê²½ê¸°'ë§Œ í•„í„°ë§í•˜ê¸° ìœ„í•œ í‚¤ì›Œë“œ ì„¸íŠ¸ ìƒì„±.
    - 'ë‚´ì¼'
    - 11.28 / 11-28 / 11/28 ê°™ì€ ì—¬ëŸ¬ ë‚ ì§œ í¬ë§·
    """
    tomorrow = get_kst_now().date() + timedelta(days=1)
    m = tomorrow.month
    d = tomorrow.day

    md_dot_1 = f"{m}.{d}"
    md_dot_2 = f"{m}.{d:02d}"
    md_dash_1 = f"{m}-{d}"
    md_dash_2 = f"{m}-{d:02d}"
    md_slash_1 = f"{m}/{d}"
    md_slash_2 = f"{m}/{d:02d}"

    return {
        "ë‚´ì¼",
        md_dot_1, md_dot_2,
        md_dash_1, md_dash_2,
        md_slash_1, md_slash_2,
    }


def get_menu_caption() -> str:
    """ë©”ì¸ ë©”ë‰´ ì„¤ëª… í…ìŠ¤íŠ¸ (ì˜¤ëŠ˜/ë‚´ì¼ ë‚ ì§œ ìë™ ë°˜ì˜)"""
    today_str, tomorrow_str = get_date_labels()
    return (
        "ğŸ“Œ ìŠ¤í¬ì¸  ì •ë³´&ë¶„ì„ ê³µìœ ë°© ë©”ë‰´ ì•ˆë‚´\n\n"
        "1ï¸âƒ£ ì‹¤ì‹œê°„ ë¬´ë£Œ ì¤‘ê³„ - GOAT-TV ë¼ì´ë¸Œ ì¤‘ê³„ ë°”ë¡œê°€ê¸°\n"
        f"2ï¸âƒ£ {today_str} ê²½ê¸° ë¶„ì„í”½ - ì¢…ëª©ë³„ë¡œ {today_str} ê²½ê¸° ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”\n"
        f"3ï¸âƒ£ {tomorrow_str} ê²½ê¸° ë¶„ì„í”½ - ì¢…ëª©ë³„ë¡œ {tomorrow_str} ê²½ê¸° ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”\n"
        "4ï¸âƒ£ ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ - ì£¼ìš” ì´ìŠˆ & ë‰´ìŠ¤ ìš”ì•½ ì •ë¦¬\n\n"
        "ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì›í•˜ëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡"
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¶„ì„/ë‰´ìŠ¤ ë°ì´í„° (ì˜ˆì‹œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ANALYSIS_TODAY = {
    "ì¶•êµ¬": [],
    "ë†êµ¬": [],
    "ì•¼êµ¬": [],
    "ë°°êµ¬": [],
}
ANALYSIS_TOMORROW = {
    "ì¶•êµ¬": [],
    "ë†êµ¬": [],
    "ì•¼êµ¬": [],
    "ë°°êµ¬": [],
}

ANALYSIS_DATA_MAP = {
    "today": ANALYSIS_TODAY,
    "tomorrow": ANALYSIS_TOMORROW,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‹¤ìŒ ìŠ¤í¬ì¸  ì¹´í…Œê³ ë¦¬ ID ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DevTools > Network ì—ì„œ harmony contents.json ìš”ì²­ í™•ì¸ í›„
# defaultCategoryId3 ì˜ value ë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¸íŒ….
DAUM_CATEGORY_IDS = {
    # í•´ì™¸ì¶•êµ¬
    "world_soccer": os.getenv("DAUM_CAT_WORLD_SOCCER", "100032"),

    # êµ­ë‚´ì¶•êµ¬ (Kë¦¬ê·¸)
    "soccer_kleague": os.getenv("DAUM_CAT_SOCCER_KLEAGUE", "1027"),

    # êµ­ë‚´ì•¼êµ¬ (KBO)
    "baseball_kbo": os.getenv("DAUM_CAT_BASEBALL_KBO", "1028"),

    # í•´ì™¸ì•¼êµ¬ (MLB)
    "baseball_world": os.getenv("DAUM_CAT_BASEBALL_WORLD", "1015"),

    # ë†êµ¬
    "basketball": os.getenv("DAUM_CAT_BASKETBALL", "1029"),

    # ë°°êµ¬
    "volleyball": os.getenv("DAUM_CAT_VOLLEYBALL", "100033"),
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_gs_client = None  # gspread í´ë¼ì´ì–¸íŠ¸ ìºì‹œìš©


def get_gs_client():
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„œë¹„ìŠ¤ê³„ì • JSON ì½ì–´ì„œ gspread í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    global _gs_client
    if _gs_client is not None:
        return _gs_client

    key_raw = os.getenv("GOOGLE_SERVICE_KEY")
    if not key_raw:
        print("[GSHEET] GOOGLE_SERVICE_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸ ì—°ë™ ê±´ë„ˆëœ€.")
        return None

    try:
        key_data = json.loads(key_raw)
    except Exception as e:
        print(f"[GSHEET] GOOGLE_SERVICE_KEY JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

    scope = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]

    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_data, scope)
    _gs_client = gspread.authorize(creds)
    print("[GSHEET] gspread ì¸ì¦ ì™„ë£Œ")
    return _gs_client


def summarize_text(text: str, max_len: int = 400) -> str:
    """
    (ì˜ˆì „ìš©) ì•„ì£¼ ë‹¨ìˆœí•œ ìš”ì•½: ë¬¸ì¥ì„ ì˜ë¼ì„œ ì•ì—ì„œë¶€í„° max_lenê¹Œì§€ ìë¥´ëŠ” ë°©ì‹.
    """
    text = text.replace("\n", " ").strip()
    sentences = re.split(r'(?<=[\.!?ë‹¤ìš”])\s+', text)
    result = ""
    for s in sentences:
        s = s.strip()
        if not s:
            continue
        if not result:
            candidate = s
        else:
            candidate = result + " " + s
        if len(candidate) > max_len:
            break
        result = candidate
    if not result:
        result = text[:max_len]
    return result


def clean_daum_body_text(text: str) -> str:
    """
    ë‹¤ìŒ ë‰´ìŠ¤ ë³¸ë¬¸ì—ì„œ ë²ˆì—­/ìš”ì•½ UI, ì–¸ì–´ ëª©ë¡, ê¸°ì í¬ë ˆë”§/ì‚¬ì§„ ì„¤ëª… ë“±
    ë¶ˆí•„ìš”í•œ ë¬¸ì¥ì„ ìµœëŒ€í•œ ì œê±°í•˜ê³  ê¸°ì‚¬ ë³¸ë¬¸ë§Œ ë‚¨ê¸´ë‹¤.
    """
    if not text:
        return ""

    # 1ë‹¨ê³„: ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³ , ë¹ˆ ì¤„ ì œê±°
    lines = [l.strip() for l in text.splitlines() if l.strip()]

    blacklist = [
        "ìŒì„±ìœ¼ë¡œ ë“£ê¸°",
        "ìŒì„± ì¬ìƒ",
        "ìŒì„±ì¬ìƒ ì„¤ì •",
        "ë²ˆì—­ ì„¤ì •",
        "ë²ˆì—­ beta",
        "Translated by",
        "ì „ì²´ ë§¥ë½ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ë³¸ë¬¸ ë³´ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
        "ìš”ì•½ë¬¸ì´ë¯€ë¡œ ì¼ë¶€ ë‚´ìš©ì´ ìƒëµë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ìš”ì•½ë³¸ì´ ìë™ìš”ì•½ ê¸°ì‚¬ ì œëª©ê³¼ ì£¼ìš” ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ìš”ì•½í•œ ê²°ê³¼ì…ë‹ˆë‹¤",
        "ê¸°ì‚¬ ì œëª©ê³¼ ì£¼ìš” ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ìš”ì•½í•œ ê²°ê³¼ì…ë‹ˆë‹¤",
        # ì–¸ì–´ ëª©ë¡ í‚¤ì›Œë“œ
        "í•œêµ­ì–´ - English",
        "í•œêµ­ì–´ - ì˜ì–´",
        "English",
        "æ—¥æœ¬èª",
        "ç®€ä½“ä¸­æ–‡",
        "Deutsch",
        "Ğ ÑƒÑÑĞºĞ¸Ğ¹",
        "EspaÃ±ol",
        "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "bahasa Indonesia",
        "à¸ à¸²à¸©à¸²à¹„à¸—à¸¢",
        "TÃ¼rkÃ§e",
    ]

    clean_lines = []
    for l in lines:
        # 1) ê³µí†µ ë¸”ë™ë¦¬ìŠ¤íŠ¸
        if any(b in l for b in blacklist):
            continue

        # 2) ì‚¬ì§„/ê¸°ì‚¬ í¬ë ˆë”§ í•œ ì¤„ í†µì§¸ë¡œ ë‚ ë¦¬ê¸°
        if re.match(r"^\[[^]]{2,60}\]\s*[^ ]{1,20}\s*(ê¸°ì|í†µì‹ ì›|íŠ¹íŒŒì›)?\s*$", l):
            continue

        clean_lines.append(l)

    text = " ".join(clean_lines)

    # 3ë‹¨ê³„: ë³¸ë¬¸ ì•ˆì— ë¼ì–´ ìˆëŠ” í¬ë ˆë”§ íŒ¨í„´ ì œê±°
    text = re.sub(
        r"\[[^]]{2,60}(ì¼ë³´|ë‰´ìŠ¤|ì½”ë¦¬ì•„|KOREA|í¬í¬íˆ¬|ë² ìŠ¤íŠ¸ ì¼ë ˆë¸)[^]]*?\]\s*[^ ]{1,20}\s*(ê¸°ì|í†µì‹ ì›|íŠ¹íŒŒì›)?",
        "",
        text,
    )
    text = re.sub(
        r"\[[^]]{2,60}\]\s*[^ ]{1,20}\s*(ê¸°ì|í†µì‹ ì›|íŠ¹íŒŒì›)",
        "",
        text,
    )

    # 4ë‹¨ê³„: "ìš”ì•½ë³´ê¸° ìë™ìš”ì•½" ê¼¬ë¦¬ ì œê±°
    text = re.sub(r"ìš”ì•½ë³´ê¸°\s*ìë™ìš”ì•½.*$", "", text)

    # 5ë‹¨ê³„: ê³µë°± ì •ë¦¬
    text = re.sub(r"\s{2,}", " ", text).strip()

    return text


def remove_title_prefix(title: str, body: str) -> str:
    """
    ë³¸ë¬¸ì´ ì œëª©ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ê·¸ ë¶€ë¶„ì„ ì˜ë¼ë‚¸ë‹¤.
    (ì œëª©ì´ ê·¸ëŒ€ë¡œ summary ì— ë°˜ë³µë˜ëŠ” í˜„ìƒ ì™„í™”ìš©)
    """
    if not title or not body:
        return body

    t = title.strip().strip('\"â€œâ€')
    b = body.strip()

    candidates = [
        t,
        f'"{t}"',
        f"â€œ{t}â€",
    ]

    for cand in candidates:
        if b.startswith(cand):
            return b[len(cand):].lstrip(" -â€“:Â·,\"'")

    return b

def parse_maz_overseas_row(tr) -> dict | None:
    """
    mazgtv í•´ì™¸ë¶„ì„ í…Œì´ë¸”ì˜ <tr> í•˜ë‚˜ì—ì„œ
    ë¦¬ê·¸ëª… / í™ˆíŒ€ / ì›ì •íŒ€ / í‚¥ì˜¤í”„ ì‹œê°„ / ìƒì„¸ ë§í¬ë¥¼ ì¶”ì¶œí•œë‹¤.
    """
    tds = tr.find_all("td")
    if len(tds) < 3:
        return None

    # í™ˆíŒ€
    home_parts = list(tds[0].stripped_strings)
    home_team = home_parts[0] if home_parts else ""

    # ê°€ìš´ë°: [ë¦¬ê·¸, VS, ë‚ ì§œ/ì‹œê°„] êµ¬ì¡°ë¼ê³  ê°€ì •
    center_parts = list(tds[1].stripped_strings)
    league = center_parts[0] if center_parts else ""
    kickoff = center_parts[-1] if center_parts else ""

    # ì›ì •íŒ€
    away_parts = list(tds[2].stripped_strings)
    away_team = away_parts[0] if away_parts else ""

    # ìƒì„¸ ë§í¬ (tr ì•ˆì— ìˆëŠ” ì²« ë²ˆì§¸ <a href>)
    a = tr.select_one("a[href]") or tr.find("a", href=True)
    url = a["href"].strip() if a and a.get("href") else ""

    return {
        "league": league.strip(),
        "home": home_team.strip(),
        "away": away_team.strip(),
        "kickoff": kickoff.strip(),
        "url": url,
    }

def _load_analysis_sheet(sh, sheet_name: str) -> dict:
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ í•œ íƒ­(today / tomorrow)ì„ ì½ì–´ì„œ
    { sport: [ {id,title,summary}, ... ] } êµ¬ì¡°ë¡œ ë³€í™˜
    """
    try:
        ws = sh.worksheet(sheet_name)
    except Exception as e:
        print(f"[GSHEET] ì‹œíŠ¸ '{sheet_name}' ì—´ê¸° ì‹¤íŒ¨: {e}")
        return {}

    rows = ws.get_all_values()
    if not rows:
        return {}

    header = rows[0]
    idx_sport = 0
    idx_id = 1
    idx_title = 2
    idx_summary = 3

    def safe_index(name, default):
        try:
            return header.index(name)
        except ValueError:
            return default

    idx_sport = safe_index("sport", idx_sport)
    idx_id = safe_index("id", idx_id)
    idx_title = safe_index("title", idx_title)
    idx_summary = safe_index("summary", idx_summary)

    data: dict[str, list[dict]] = {}

    for row in rows[1:]:
        if len(row) <= idx_title:
            continue

        sport = (row[idx_sport] if len(row) > idx_sport else "").strip()
        if not sport:
            continue

        item_id = (row[idx_id] if len(row) > idx_id else "").strip()
        title = (row[idx_title] if len(row) > idx_title else "").strip()
        summary = (row[idx_summary] if len(row) > idx_summary else "").strip()

        if not title:
            continue

        if not item_id:
            cur_len = len(data.get(sport, []))
            item_id = f"{sport}_{cur_len + 1}"

        entry = {
            "id": item_id,
            "title": title,
            "summary": summary,
        }
        data.setdefault(sport, []).append(entry)

    return data


def reload_analysis_from_sheet():
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ today / tomorrow íƒ­ì„ ì½ì–´ì„œ
    ANALYSIS_TODAY / ANALYSIS_TOMORROW / ANALYSIS_DATA_MAP ê°±ì‹ 
    """
    global ANALYSIS_TODAY, ANALYSIS_TOMORROW, ANALYSIS_DATA_MAP

    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not client or not spreadsheet_id:
        print("[GSHEET] ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” SPREADSHEET_ID ì—†ìŒ â†’ ê¸°ì¡´ í•˜ë“œì½”ë”© ë°ì´í„° ì‚¬ìš©")
        return

    try:
        sh = client.open_by_key(spreadsheet_id)
    except Exception as e:
        print(f"[GSHEET] ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° ì‹¤íŒ¨: {e}")
        return

    sheet_today_name = os.getenv("SHEET_TODAY_NAME", "today")
    sheet_tomorrow_name = os.getenv("SHEET_TOMORROW_NAME", "tomorrow")

    print(f"[GSHEET] '{sheet_today_name}' / '{sheet_tomorrow_name}' íƒ­ì—ì„œ ë¶„ì„ ë°ì´í„° ë¡œë”© ì‹œë„")

    try:
        today_data = _load_analysis_sheet(sh, sheet_today_name)
        tomorrow_data = _load_analysis_sheet(sh, sheet_tomorrow_name)
    except Exception as e:
        print(f"[GSHEET] ì‹œíŠ¸ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return

    ANALYSIS_TODAY = today_data
    ANALYSIS_TOMORROW = tomorrow_data

    ANALYSIS_DATA_MAP = {
        "today": ANALYSIS_TODAY,
        "tomorrow": ANALYSIS_TOMORROW,
    }

    print("[GSHEET] ANALYSIS_TODAY / ANALYSIS_TOMORROW ê°±ì‹  ì™„ë£Œ")

def append_analysis_rows(day_key: str, rows: list[list[str]]) -> bool:
    """
    ë¶„ì„ ë°ì´í„°ë¥¼ today / tomorrow íƒ­ì— ì¶”ê°€í•˜ëŠ” ê³µìš© í•¨ìˆ˜.
    rows: [ [sport, "", title, summary], ... ]
    """
    client_gs = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not (client_gs and spreadsheet_id):
        print("[GSHEET][ANALYSIS] ì„¤ì • ì—†ìŒ â†’ ì €ì¥ ë¶ˆê°€")
        return False

    sheet_today_name = os.getenv("SHEET_TODAY_NAME", "today")
    sheet_tomorrow_name = os.getenv("SHEET_TOMORROW_NAME", "tomorrow")
    sheet_name = sheet_today_name if day_key == "today" else sheet_tomorrow_name

    try:
        sh = client_gs.open_by_key(spreadsheet_id)
        ws = sh.worksheet(sheet_name)
    except Exception as e:
        print(f"[GSHEET][ANALYSIS] ì‹œíŠ¸ '{sheet_name}' ì—´ê¸° ì‹¤íŒ¨: {e}")
        return False

    try:
        ws.append_rows(rows, value_input_option="RAW")
        print(f"[GSHEET][ANALYSIS] {sheet_name} ì— {len(rows)}ê±´ ì¶”ê°€")
        return True
    except Exception as e:
        print(f"[GSHEET][ANALYSIS] append_rows ì˜¤ë¥˜: {e}")
        return False


NEWS_DATA = {}


def _load_news_sheet(sh, sheet_name: str) -> dict:
    """
    êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë‰´ìŠ¤ íƒ­ì„ ì½ì–´ì„œ
    {
        sport: [ {id,title,summary}, ... ]
    } êµ¬ì¡°ë¡œ ë³€í™˜
    """
    try:
        ws = sh.worksheet(sheet_name)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ì‹œíŠ¸ '{sheet_name}' ì—´ê¸° ì‹¤íŒ¨: {e}")
        return {}

    rows = ws.get_all_values()
    if not rows:
        return {}

    header = rows[0]

    idx_sport = 0
    idx_id = 1
    idx_title = 2
    idx_summary = 3

    def safe_index(name, default):
        try:
            return header.index(name)
        except ValueError:
            return default

    idx_sport = safe_index("sport", idx_sport)
    idx_id = safe_index("id", idx_id)
    idx_title = safe_index("title", idx_title)
    idx_summary = safe_index("summary", idx_summary)

    data: dict[str, list[dict]] = {}

    for row in rows[1:]:
        if len(row) <= idx_title:
            continue

        sport = (row[idx_sport] if len(row) > idx_sport else "").strip()
        if not sport:
            continue

        item_id = (row[idx_id] if len(row) > idx_id else "").strip()
        title = (row[idx_title] if len(row) > idx_title else "").strip()
        summary = (row[idx_summary] if len(row) > idx_summary else "").strip()

        if not title:
            continue

        if not item_id:
            cur_len = len(data.get(sport, []))
            item_id = f"{sport}_news_{cur_len + 1}"

        entry = {
            "id": item_id,
            "title": title,
            "summary": summary,
        }
        data.setdefault(sport, []).append(entry)

    return data


def reload_news_from_sheet():
    """êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë‰´ìŠ¤ íƒ­ì„ ì½ì–´ì„œ NEWS_DATA ê°±ì‹ """
    global NEWS_DATA
    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not client or not spreadsheet_id:
        print("[GSHEET] ë‰´ìŠ¤ìš© SPREADSHEET ì—°ë™ ì‹¤íŒ¨ â†’ ê¸°ì¡´ í•˜ë“œì½”ë”© NEWS_DATA ì‚¬ìš©.")
        return

    try:
        sh = client.open_by_key(spreadsheet_id)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° ì‹¤íŒ¨: {e}")
        return

    sheet_news_name = os.getenv("SHEET_NEWS_NAME", "news")
    print(f"[GSHEET] '{sheet_news_name}' íƒ­ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì‹œë„")

    try:
        news_data = _load_news_sheet(sh, sheet_news_name)
    except Exception as e:
        print(f"[GSHEET] ë‰´ìŠ¤ ì‹œíŠ¸ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return

    NEWS_DATA = news_data
    print("[GSHEET] NEWS_DATA ê°±ì‹  ì™„ë£Œ")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‚¤ë³´ë“œ/ë©”ë‰´ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_reply_keyboard() -> ReplyKeyboardMarkup:
    """ë´‡ 1:1 í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨ í•˜ë‹¨ í‚¤ë³´ë“œ"""
    menu = [
        ["ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°", "ë„ì›€ë§"],
    ]
    return ReplyKeyboardMarkup(menu, resize_keyboard=True)


def build_main_inline_menu() -> InlineKeyboardMarkup:
    """
    ë©”ì¸ ì¸ë¼ì¸ ë©”ë‰´ (ì±„ë„/ë¯¸ë¦¬ë³´ê¸° ê³µí†µ)
    ì±„ë„ì—ì„œëŠ” ì´ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê°ì ë´‡ DMìœ¼ë¡œ ì´ë™í•˜ê²Œ í•¨.
    """
    today_str, tomorrow_str = get_date_labels()

    buttons = [
        [InlineKeyboardButton("ì‹¤ì‹œê°„ ë¬´ë£Œ ì¤‘ê³„", url="https://goat-tv.com")],
        [
            InlineKeyboardButton(
                f"{today_str} ê²½ê¸° ë¶„ì„í”½",
                url=f"https://t.me/{BOT_USERNAME}?start=today",
            )
        ],
        [
            InlineKeyboardButton(
                f"{tomorrow_str} ê²½ê¸° ë¶„ì„í”½",
                url=f"https://t.me/{BOT_USERNAME}?start=tomorrow",
            )
        ],
        [
            InlineKeyboardButton(
                "ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½",
                url=f"https://t.me/{BOT_USERNAME}?start=news",
            )
        ],
    ]
    return InlineKeyboardMarkup(buttons)


def build_analysis_category_menu(key: str) -> InlineKeyboardMarkup:
    # key = "today" or "tomorrow"
    buttons = [
        [InlineKeyboardButton("âš½ï¸ì¶•êµ¬âš½ï¸", callback_data=f"analysis_cat:{key}:ì¶•êµ¬")],
        [InlineKeyboardButton("ğŸ€ë†êµ¬ğŸ€", callback_data=f"analysis_cat:{key}:ë†êµ¬")],
        [InlineKeyboardButton("âš¾ï¸ì•¼êµ¬âš¾ï¸", callback_data=f"analysis_cat:{key}:ì•¼êµ¬")],
        [InlineKeyboardButton("ğŸë°°êµ¬ğŸ", callback_data=f"analysis_cat:{key}:ë°°êµ¬")],
        [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
    ]
    return InlineKeyboardMarkup(buttons)


def build_analysis_match_menu(key: str, sport: str) -> InlineKeyboardMarkup:
    """ì¢…ëª© ì„ íƒ í›„ â†’ í•´ë‹¹ ì¢…ëª© ê²½ê¸° ë¦¬ìŠ¤íŠ¸ ë©”ë‰´"""
    items = ANALYSIS_DATA_MAP.get(key, {}).get(sport, [])
    buttons = []
    for item in items:
        cb = f"match:{key}:{sport}:{item['id']}"
        buttons.append([InlineKeyboardButton(item["title"], callback_data=cb)])

    buttons.append([InlineKeyboardButton("â—€ ì¢…ëª© ì„ íƒìœ¼ë¡œ", callback_data=f"analysis_root:{key}")])
    buttons.append([InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")])
    return InlineKeyboardMarkup(buttons)


def build_news_category_menu() -> InlineKeyboardMarkup:
    """ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ â†’ ì¢…ëª© ì„ íƒ ë©”ë‰´"""
    buttons = [
        [InlineKeyboardButton("âš½ï¸ì¶•êµ¬ ë‰´ìŠ¤âš½ï¸", callback_data="news_cat:ì¶•êµ¬")],
        [InlineKeyboardButton("ğŸ€ë†êµ¬ ë‰´ìŠ¤ğŸ€", callback_data="news_cat:ë†êµ¬")],
        [InlineKeyboardButton("âš¾ï¸ì•¼êµ¬ ë‰´ìŠ¤âš¾ï¸", callback_data="news_cat:ì•¼êµ¬")],
        [InlineKeyboardButton("ğŸë°°êµ¬ ë‰´ìŠ¤ğŸ", callback_data="news_cat:ë°°êµ¬")],
        [InlineKeyboardButton("ê¸°íƒ€ì¢…ëª© ë‰´ìŠ¤", callback_data="news_cat:ê¸°íƒ€ì¢…")],
        [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
    ]
    return InlineKeyboardMarkup(buttons)


def build_news_list_menu(sport: str) -> InlineKeyboardMarkup:
    """ì¢…ëª© ì„ íƒ í›„ â†’ í•´ë‹¹ ì¢…ëª© ë‰´ìŠ¤ ì œëª© ë¦¬ìŠ¤íŠ¸ ë©”ë‰´"""
    items = NEWS_DATA.get(sport, [])
    buttons = []
    for item in items:
        cb = f"news_item:{sport}:{item['id']}"
        buttons.append([InlineKeyboardButton(item["title"], callback_data=cb)])

    buttons.append([InlineKeyboardButton("â—€ ì¢…ëª© ì„ íƒìœ¼ë¡œ", callback_data="news_root")])
    buttons.append([InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")])
    return InlineKeyboardMarkup(buttons)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ: ë©”ì¸ ë©”ë‰´ ë³´ë‚´ëŠ” í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def send_main_menu(chat_id: int | str, context: ContextTypes.DEFAULT_TYPE, preview: bool = False):
    """
    ì±„ë„/DM ê³µí†µìœ¼ë¡œ 'í…ìŠ¤íŠ¸ + ë©”ì¸ ë©”ë‰´ ë²„íŠ¼' ì „ì†¡.
    """
    msg = await context.bot.send_message(
        chat_id=chat_id,
        text=get_menu_caption(),
        reply_markup=build_main_inline_menu(),
    )
    return msg


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•¸ë“¤ëŸ¬ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1) /start â€“ DMì—ì„œ ì±„ë„ê³¼ ë™ì¼í•œ ë ˆì´ì•„ì›ƒ or ë°”ë¡œ ë©”ë‰´ ì§„ì…
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    args = context.args
    mode = args[0] if args else None

    today_str, tomorrow_str = get_date_labels()

    if mode == "today":
        await update.message.reply_text(
            f"{today_str} ê²½ê¸° ë¶„ì„í”½ ë©”ë‰´ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_analysis_category_menu("today"),
        )
        return

    if mode == "tomorrow":
        await update.message.reply_text(
            f"{tomorrow_str} ê²½ê¸° ë¶„ì„í”½ ë©”ë‰´ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_analysis_category_menu("tomorrow"),
        )
        return

    if mode == "news":
        await update.message.reply_text(
            "ìŠ¤í¬ì¸  ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤. ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš” ğŸ‘‡",
            reply_markup=build_news_category_menu(),
        )
        return

    await update.message.reply_text(
        "ìŠ¤í¬ì¸ ë´‡ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ì—ëŠ” ì±„ë„ì— ì˜¬ë¼ê°ˆ ë©”ë‰´ì™€ ë™ì¼í•œ ë ˆì´ì•„ì›ƒ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë³´ì—¬ì¤„ê²Œ.\n"
        "ì‹¤ì œ ì±„ë„ ë°°í¬ëŠ” /publish ëª…ë ¹ìœ¼ë¡œ ì§„í–‰í•˜ë©´ ë¼.",
        reply_markup=build_reply_keyboard(),
    )

    await send_main_menu(chat_id, context, preview=True)


async def myid(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    await update.message.reply_text(f"ë‹¹ì‹ ì˜ í…”ë ˆê·¸ë¨ ID: {uid}")


# 2) DM í…ìŠ¤íŠ¸ ì²˜ë¦¬ â€“ ê°„ë‹¨ í…ŒìŠ¤íŠ¸ìš©
async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    if "ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°" in text:
        await start(update, context)
    elif "ë„ì›€ë§" in text:
        await update.message.reply_text(
            "/start : ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°\n"
            "/publish : ì±„ë„ì— ë©”ë‰´ ì „ì†¡ + ìƒë‹¨ ê³ ì •"
        )
    else:
        await update.message.reply_text("ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°ëŠ” /start ë˜ëŠ” 'ë©”ë‰´ ë¯¸ë¦¬ë³´ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")


# 3) /publish â€“ ì±„ë„ë¡œ ë©”ë‰´ ë³´ë‚´ê³  ìƒë‹¨ ê³ ì •
async def publish(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    if not CHANNEL_ID:
        await update.message.reply_text("CHANNEL_IDê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. Render í™˜ê²½ë³€ìˆ˜ì— CHANNEL_IDë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return

    try:
        await context.bot.unpin_all_chat_messages(CHANNEL_ID)
    except Exception:
        pass

    msg = await send_main_menu(CHANNEL_ID, context, preview=False)

    await context.bot.pin_chat_message(
        chat_id=CHANNEL_ID,
        message_id=msg.message_id,
        disable_notification=True,
    )

    await update.message.reply_text("ì±„ë„ì— ë©”ë‰´ë¥¼ ì˜¬ë¦¬ê³  ìƒë‹¨ì— ê³ ì •í–ˆìŠµë‹ˆë‹¤ âœ…")


# 5) /syncsheet â€“ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë¶„ì„/ë‰´ìŠ¤ ë°ì´í„° ë‹¤ì‹œ ë¡œë”©
async def syncsheet(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    try:
        reload_analysis_from_sheet()
        reload_news_from_sheet()
        await update.message.reply_text("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë¶„ì„ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤ âœ…")
    except Exception as e:
        await update.message.reply_text(f"êµ¬ê¸€ì‹œíŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# ğŸ”¹ /newsclean â€“ news ì‹œíŠ¸ ì´ˆê¸°í™” (í—¤ë”ë§Œ ë‚¨ê¸°ê¸°)
async def newsclean(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    client_gs = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not (client_gs and spreadsheet_id):
        await update.message.reply_text(
            "êµ¬ê¸€ì‹œíŠ¸ ì„¤ì •(GOOGLE_SERVICE_KEY ë˜ëŠ” SPREADSHEET_ID)ì´ ì—†ì–´ ì‹œíŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
        return

    try:
        sh = client_gs.open_by_key(spreadsheet_id)
        ws = sh.worksheet(os.getenv("SHEET_NEWS_NAME", "news"))
    except Exception as e:
        await update.message.reply_text(f"ë‰´ìŠ¤ ì‹œíŠ¸ë¥¼ ì—´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        return

    try:
        rows = ws.get_all_values()
        if rows:
            header = rows[0]
        else:
            header = ["sport", "id", "title", "summary"]

        ws.clear()
        ws.update("A1", [header])

        await update.message.reply_text("ë‰´ìŠ¤ ì‹œíŠ¸ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤. (í—¤ë”ë§Œ ë‚¨ê²¨ë‘ ) âœ…")

    except Exception as e:
        await update.message.reply_text(f"ì‹œíŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        return


# ğŸ”¹ 4) /rollover â€“ ë‚´ì¼ ë¶„ì„ â†’ ì˜¤ëŠ˜ ë¶„ì„ìœ¼ë¡œ ë³µì‚¬
async def rollover(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    client = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if client and spreadsheet_id:
        try:
            sh = client.open_by_key(spreadsheet_id)

            sheet_today_name = os.getenv("SHEET_TODAY_NAME", "today")
            sheet_tomorrow_name = os.getenv("SHEET_TOMORROW_NAME", "tomorrow")

            ws_today = sh.worksheet(sheet_today_name)
            ws_tomorrow = sh.worksheet(sheet_tomorrow_name)

            rows = ws_tomorrow.get_all_values()

            if rows:
                ws_today.clear()
                ws_today.update("A1", rows)

                header = rows[0]
                ws_tomorrow.clear()
                ws_tomorrow.update("A1", [header])
            else:
                print("[GSHEET] tomorrow íƒ­ì— ë°ì´í„°ê°€ ì—†ì–´ ì‹œíŠ¸ ë¡¤ì˜¤ë²„ëŠ” ìƒëµí•©ë‹ˆë‹¤.")

        except Exception as e:
            print(f"[GSHEET] ë¡¤ì˜¤ë²„ ì¤‘ ì‹œíŠ¸ ë³µì‚¬ ì‹¤íŒ¨: {e}")

    else:
        print("[GSHEET] í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” SPREADSHEET_ID ì—†ìŒ â†’ ì‹œíŠ¸ ë¡¤ì˜¤ë²„ëŠ” ê±´ë„ˆëœ€.")

    reload_analysis_from_sheet()

    await update.message.reply_text(
        "âœ… ë¡¤ì˜¤ë²„ ì™„ë£Œ!\n"
        "êµ¬ê¸€ì‹œíŠ¸ 'tomorrow' íƒ­ ë‚´ìš©ì„ 'today' íƒ­ìœ¼ë¡œ ë³µì‚¬í–ˆê³ ,\n"
        "'tomorrow' íƒ­ì€ í—¤ë”ë§Œ ë‚¨ê¸°ê³  ì´ˆê¸°í™”í–ˆì–´.\n\n"
        "ì´ì œ ì˜¤ëŠ˜ ê²½ê¸° ë¶„ì„ì€ 'today' íƒ­ì—ì„œ, ë‚´ì¼ ê²½ê¸°ëŠ” 'tomorrow' íƒ­ì—ì„œ ì‘ì„±í•˜ë©´ ë¼."
    )


def simple_summarize(text: str, max_chars: int = 400) -> str:
    """
    ì•„ì£¼ ë‹¨ìˆœ ìš”ì•½: ë¬¸ì¥ ì‚¬ì´ ê³µë°± ì •ë¦¬ í›„,
    max_chars ì•ˆìª½ì—ì„œ 'ë‹¤.' ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ì„œ ë°˜í™˜.
    (Gemini ì˜¤ë¥˜ ì‹œ fallback ìš©)
    """
    if not text:
        return ""

    text = re.sub(r"\s+", " ", text).strip()

    if len(text) <= max_chars:
        return text

    cut = text.rfind("ë‹¤.", 0, max_chars)
    if cut != -1:
        return text[: cut + 2]

    return text[:max_chars] + "..."

# ğŸ”¹ OpenAI í´ë¼ì´ì–¸íŠ¸ (ìš”ì•½ìš©)
_openai_client = None

def get_openai_client():
    """
    OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•´ì„œ ëŒë ¤ì¤€ë‹¤.
    í‚¤ê°€ ì—†ìœ¼ë©´ Noneì„ ë¦¬í„´í•˜ê³ , ì—ëŸ¬ ì‹œ simple_summarize í´ë°±ì„ ì‚¬ìš©í•œë‹¤.
    """
    global _openai_client
    if _openai_client is not None:
        return _openai_client

    api_key = os.getenv("OPENAI_API_KEY", "").strip()
    if not api_key:
        print("[OPENAI] OPENAI_API_KEY ë¯¸ì„¤ì • â†’ simple_summarize í´ë°± ì‚¬ìš©")
        return None

    try:
        _openai_client = OpenAI(api_key=api_key)
        print("[OPENAI] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"[OPENAI] í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        _openai_client = None
    return _openai_client

def ensure_team_line_breaks(body: str, home_team: str, away_team: str) -> str:
    """
    ìš”ì•½ ë³¸ë¬¸ì—ì„œ 'í™ˆíŒ€: ... ì›ì •íŒ€:' ì´ í•œ ì¤„ì— ë¶™ì–´ ìˆì„ ë•Œ
    í™ˆíŒ€ ë¸”ë¡ / ì›ì •íŒ€ ë¸”ë¡ / ğŸ¯ í”½ ì‚¬ì´ì— ë¹ˆ ì¤„ì„ ê°•ì œë¡œ ë„£ì–´ ì¤€ë‹¤.
    """
    if not body:
        return body

    # í™ˆíŒ€: ... ì›ì •íŒ€: â†’ ì¤‘ê°„ì— ë¹ˆ ì¤„ ì‚½ì…
    if home_team:
        pattern = rf"({re.escape(home_team)}:[^\n]+)\s+({re.escape(away_team)}:)"
        body = re.sub(pattern, r"\1\n\n\2", body)

    # ì›ì •íŒ€: ... ğŸ¯ í”½ â†’ ì¤‘ê°„ì— ë¹ˆ ì¤„
    if away_team:
        pattern2 = rf"({re.escape(away_team)}:[^\n]+)\s+ğŸ¯\s*í”½"
        body = re.sub(pattern2, r"\1\n\nğŸ¯ í”½", body)

    # ğŸ¯ í”½ ë¼ì¸ ìì²´ê°€ í•œ ì¤„ì— ë­‰ì³ ìˆìœ¼ë©´ ì¤„ë°”ê¿ˆ ì •ë¦¬
    body = re.sub(r"ğŸ¯\s*í”½\s*[\n ]*â¡", "ğŸ¯ í”½\nâ¡", body)

    # ì—¬ëŸ¬ ê°œ ê³µë°±ì„ ì¼ë°˜ ê³µë°±ìœ¼ë¡œ ì •ë¦¬
    body = re.sub(r"[ \t]+", " ", body)
    return body.strip()

# ğŸ”¹ mazgtv í™ë³´ ë¬¸êµ¬/í•´ì‹œíƒœê·¸ ê³µí†µ ì œê±°ìš© íŒ¨í„´
MAZ_REMOVE_PATTERNS = [
    # ê¸°ë³¸ í™ë³´ ë¬¸êµ¬
    r"ì‹¤ì‹œê°„\s*ìŠ¤í¬ì¸ ì¤‘ê³„",
    r"ìŠ¤í¬ì¸ \s*ì¤‘ê³„",
    r"ìŠ¤í¬ì¸ \s*ë¶„ì„",
    r"ìŠ¤í¬ì¸ \s*ì •ë³´",
    r"ë¼ì´ë¸Œ\s*ìŠ¤í¬ì¸ ì¤‘ê³„",
    r"ì‹¤ì‹œê°„\s*ë¬´ë£Œ\s*ì¤‘ê³„",
    r"ë¬´ë£Œ\s*ì¤‘ê³„",
    r"ë¬´ë£Œ\s*ìŠ¤í¬ì¸ ì¤‘ê³„",

    # ì‚¬ì´íŠ¸/ë¸Œëœë“œëª…
    r"ë§ˆì§•ê°€í‹°ë¹„",
    r"ë§ˆì§•ê°€\s*í‹°ë¹„",
    r"ë§ˆì§•ê°€TV",
    r"ë§ˆì§•ê°€\s*TV",
    r"ë§ˆì§•ê°€\s*í‹°ë¸Œì´",
    r"ë§ˆì§•ê°€\s*í‹°ë¹„\s*ë°”ë¡œê°€ê¸°",

    # ë°°ë„ˆ/ìœ ë„ ë¬¸êµ¬
    r"ë°°ë„ˆ\s*ë¬¸ì˜",
    r"ë°°ë„ˆ",
    r"ë§í¬\s*í´ë¦­",
    r"ë°”ë¡œê°€ê¸°",
    r"ìŠ¤í¬ì¸ ì¤‘ê³„\s*ë°”ë¡œê°€ê¸°",

    # í•´ì‹œíƒœê·¸
    r"#\S+",

    # ë‚ ì§œ/ì œëª© ë¼ì¸ (ì˜ˆ: 11ì›” 28ì¼ í”„ë¦¬ë·°, 11ì›” 28ì¼ ê²½ê¸° ë¶„ì„)
    r"11ì›”\s*\d{1,2}\s*[^\n]{0,30}",
    r"\d{1,2}ì›”\s*\d{1,2}ì¼\s*[^\n]{0,30}",

    # ì œëª© íŒ¨í„´ (ì¤‘ê³„ / ë¶„ì„)
    r"[ê°€-í£A-Za-z0-9 ]+ ì¤‘ê³„",
    r"[ê°€-í£A-Za-z0-9 ]+ ë¶„ì„",
    r"[ê°€-í£A-Za-z0-9 ]+ í”„ë¦¬ë·°",

    # ì„¹ì…˜ ì œëª©ë“¤
    r"í”„ë¦¬ë·°",
    r"í•µì‹¬\s*í¬ì¸íŠ¸",
    r"í•µì‹¬\s*í¬ì¸íŠ¸\s*ì •ë¦¬",
    r"ìŠ¹ë¶€\s*ì˜ˆì¸¡",
    r"ë² íŒ…\s*ê°•ë„",
    r"ë§ˆë¬´ë¦¬\s*ì½”ë©˜íŠ¸",
    r"ë§ˆë¬´ë¦¬\s*ì •ë¦¬",

    # ì‚¬ì´íŠ¸ë¡œ ìœ ë„í•˜ëŠ” ê¼¬ë¦¬ ë¬¸êµ¬
    r"ì—ì„œ\s*í™•ì¸í•˜ì„¸ìš”[^\n]*",

    # í”½ ë¼ì¸ (ìŠ¹/ë¬´/íŒ¨, í•¸ë””, ì–¸ë”ì˜¤ë²„)
    r"\[ìŠ¹/ë¬´/íŒ¨\][^\n]+",
    r"\[í•¸ë””\][^\n]+",
    r"\[ì–¸ë”ì˜¤ë²„\][^\n]+",
    r"ìŠ¹íŒ¨\s*ì¶”ì²œ[^\n]*",
    r"ì¶”ì²œ\s*í”½[^\n]*",

    # ì´ëª¨ì§€/ì•„ì´ì½˜ë¥˜
    r"âœ…",
    r"â­•",
    r"âš ï¸",
    r"â­+",
    r"ğŸ”¥",
    r"ğŸ‘‰",
]

def clean_maz_text(text: str) -> str:
    """
    mazgtv ì›ë¬¸/ìš”ì•½ì—ì„œ í™ë³´ ë¬¸êµ¬, í•´ì‹œíƒœê·¸ ë“±ì„ ì œê±°í•˜ê³ 
    ê³µë°±ì„ ì •ë¦¬í•´ì„œ ëŒë ¤ì¤€ë‹¤.
    """
    if not text:
        return ""
    for pattern in MAZ_REMOVE_PATTERNS:
        text = re.sub(pattern, "", text, flags=re.IGNORECASE)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def extract_mmdd_from_kickoff(kickoff: str) -> tuple[int | None, int | None]:
    """
    '11-28 (ê¸ˆ) 02:45' ê°™ì€ ë¬¸ìì—´ì—ì„œ (month, day)ë¥¼ ë½‘ëŠ”ë‹¤.
    ë‹¤ë¥¸ í¬ë§·(ì˜ˆ: '11ì›” 28ì¼ 02:45')ë„ ëŒ€ë¹„í•´ì„œ ì •ê·œì‹ ë‘ ê°œë¥¼ ì‹œë„.
    """
    if not kickoff:
        return (None, None)

    text = kickoff.strip()

    # 1) 11-28 (ê¸ˆ) 02:45 í˜•íƒœ
    m = re.search(r"(\d{1,2})\s*-\s*(\d{1,2})", text)
    if not m:
        # 2) 11ì›” 28ì¼ (ê¸ˆ) 02:45 í˜•íƒœ
        m = re.search(r"(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼", text)

    if not m:
        return (None, None)

    try:
        month = int(m.group(1))
        day = int(m.group(2))
        return (month, day)
    except ValueError:
        return (None, None)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ê¸° ë¶„ì„ìš© Gemini ìš”ì•½ í•¨ìˆ˜ (íŒ€ë³„ + í”½ í˜•ì‹) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def summarize_analysis_with_gemini(
    full_text: str,
    *,
    league: str = "í•´ì™¸ì¶•êµ¬",
    home_team: str = "",
    away_team: str = "",
    max_chars: int = 900,
) -> tuple[str, str]:
    """
    ğŸ‘‰ ì´ì œëŠ” Gemini ëŒ€ì‹  OpenAI(gpt-4.1-mini)ë¥¼ ì‚¬ìš©í•´ì„œ
       'ì œëª© + íŒ€ë³„ ìš”ì•½ + ğŸ¯ í”½' í˜•ì‹ìœ¼ë¡œ ê²½ê¸° ë¶„ì„ì„ ìƒì„±í•œë‹¤.

    - return:
        new_title: ì‹œíŠ¸ title ì»¬ëŸ¼ì— ë“¤ì–´ê°ˆ ì œëª©
        summary  : ì•„ë˜ì™€ ê°™ì€ í¬ë§·ì˜ í…ìŠ¤íŠ¸

        í™ˆíŒ€ì´ë¦„:
        ...

        ì›ì •íŒ€ì´ë¦„:
        ...

        ğŸ¯ í”½
        â¡ï¸ ...
        â¡ï¸ ...
        â¡ï¸ ...
    """

    client_oa = get_openai_client()

    # ê¸°ë³¸ ì œëª©
    if home_team and away_team:
        base_title = f"[{league}] {home_team} vs {away_team} ê²½ê¸° ë¶„ì„"
    else:
        base_title = f"[{league}] í•´ì™¸ì¶•êµ¬ ê²½ê¸° ë¶„ì„"

    # ì›ë¬¸ ì •ë¦¬ (í™ë³´ ë¬¸êµ¬ ì œê±°)
    full_text_clean = clean_maz_text(full_text or "").strip()
    if len(full_text_clean) > 7000:
        full_text_clean = full_text_clean[:7000]

    # ğŸ”¸ OpenAI í‚¤ ì—†ê±°ë‚˜ í´ë¼ì´ì–¸íŠ¸ ì‹¤íŒ¨ â†’ ì˜ˆì „ simple_summarize í´ë°±
    if not client_oa:
        print("[OPENAI][ANALYSIS] í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ â†’ simple_summarize í´ë°±")
        home_label = home_team or "í™ˆíŒ€"
        away_label = away_team or "ì›ì •íŒ€"
        core = simple_summarize(full_text_clean, max_chars=max_chars)
        body = (
            f"{home_label} & {away_label}:\n"
            f"{core}\n\n"
            "ğŸ¯ í”½\n"
            "â¡ï¸ ê²½ê¸° íë¦„ ì°¸ê³ ìš© í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
            "â¡ï¸ ì‹¤ì œ ë² íŒ… ì „ ë¼ì¸Â·ë¶€ìƒ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "â¡ï¸ ì„¸ë¶€ ì¶”ì²œí”½ì€ ë³„ë„ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
        return (base_title or "[ê²½ê¸° ë¶„ì„]", body)

    # â”€â”€â”€â”€â”€ OpenAI í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€
    home_label = home_team or "í™ˆíŒ€"
    away_label = away_team or "ì›ì •íŒ€"

    prompt = f"""
ë‹¤ìŒì€ í•´ì™¸ì¶•êµ¬ ê²½ê¸° ë¶„ì„ ì›ë¬¸ì´ë‹¤.
ì „ì²´ ë‚´ìš©ì„ ì´í•´í•œ ë’¤, ì•„ë˜ì— ì œì‹œí•œ â€˜ì—„ê²©í•œ í˜•ì‹â€™ ê·¸ëŒ€ë¡œ ì‘ì„±í•˜ë¼.
âš ï¸ ì›ë¬¸ ë¬¸ì¥ ê·¸ëŒ€ë¡œ ë² ë¼ì§€ ë§ê³  ë°˜ë“œì‹œ ì¬ì‘ì„±í•˜ê³ , í˜•ì‹ì—ì„œ ë²—ì–´ë‚˜ëŠ” í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼.

ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ë¥¼ ì •í™•íˆ ì§€ì¼œë¼:

ì œëª©: [ë¦¬ê·¸] í™ˆíŒ€ vs ì›ì •íŒ€ ê²½ê¸° ë¶„ì„
ìš”ì•½:
í™ˆíŒ€:
- ë¬¸ì¥1
- ë¬¸ì¥2
(ë¬¸ì¥ ìˆ˜ëŠ” 2~3ê°œ, ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)

ì›ì •íŒ€:
- ë¬¸ì¥1
- ë¬¸ì¥2
(ë¬¸ì¥ ìˆ˜ëŠ” 2~3ê°œ)

ğŸ¯ í”½
â¡ï¸ í™ˆíŒ€/ì›ì •íŒ€ ìŠ¹ ê´€ë ¨ 1ì¤„
â¡ï¸ í•¸ë”” ê´€ë ¨ 1ì¤„
â¡ï¸ ì˜¤ë²„/ì–¸ë” ê´€ë ¨ 1ì¤„

â— ì ˆëŒ€ ê¸ˆì§€:
- í”½ ì„¹ì…˜ì— ì„¤ëª…ë¬¸ ì¶”ê°€ ê¸ˆì§€
- í”½ì„ 3ì¤„ ì´ˆê³¼í•˜ê±°ë‚˜ fewer than 3ì¤„ ê¸ˆì§€
- í™ˆíŒ€/ì›ì •íŒ€ ë¸”ë¡ ì‚¬ì´ ì¤„ë°”ê¿ˆ ëˆ„ë½ ê¸ˆì§€
- í™ˆíŒ€ê³¼ ì›ì •íŒ€ ì´ë¦„ ì—†ì´ ë¶„ì„ ì‹œì‘ ê¸ˆì§€
- ğŸ¯ í”½ ìœ„ì— ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€
- í˜•ì‹ê³¼ ë‹¤ë¥¸ ì—¬ë¶„ ë¬¸ì¥ ì¶œë ¥ ê¸ˆì§€

ì•„ë˜ëŠ” ë¦¬ê·¸/íŒ€ ì •ë³´ë‹¤.
        "\n"
        f"ë¦¬ê·¸: {league}\n"
        f"í™ˆíŒ€: {home_label}\n"
        f"ì›ì •íŒ€: {away_label}\n"
        "\n"
        "===== ê²½ê¸° ë¶„ì„ ì›ë¬¸ =====\n"
        f"{full_text_clean}\n"
    )

    try:
        resp = client_oa.chat.completions.create(
            model=os.getenv("OPENAI_MODEL_ANALYSIS", "gpt-4.1-mini"),
            messages=[
                {
                    "role": "system",
                    "content": "ë„ˆëŠ” ì¶•êµ¬ ê²½ê¸° ë¶„ì„ì„ ìš”ì•½í•´ì„œ ì •ë¦¬í•˜ëŠ” í•œêµ­ì–´ ì „ë¬¸ê°€ë‹¤. "
                               "ë¬¸ì¥ì€ ê°„ê²°í•˜ê³  ì§ì„¤ì ìœ¼ë¡œ ì“°ê³ , í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¨ë‹¤.",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.4,
            max_completion_tokens=700,
        )
        text_out = (resp.choices[0].message.content or "").strip()
        if not text_out:
            raise ValueError("empty response from OpenAI (analysis)")

        # â”€â”€â”€â”€â”€ 1ë‹¨ê³„: ì œëª©/ë³¸ë¬¸ ë¶„ë¦¬ (ì œëª©: / ìš”ì•½:) â”€â”€â”€â”€â”€
        new_title = ""
        body = ""

        m_title = re.search(r"ì œëª©\s*[:ï¼š]\s*(.+)", text_out)
        if m_title:
            new_title = m_title.group(1).strip()

        m_body = re.search(r"ìš”ì•½\s*[:ï¼š]\s*(.+)", text_out, flags=re.S)
        if m_body:
            body = m_body.group(1).strip()
        else:
            body = text_out

        if not new_title:
            new_title = base_title or "[ê²½ê¸° ë¶„ì„]"

        body = remove_title_prefix(new_title, body)
        body = clean_maz_text(body)

        # íŒ€ë³„ ì¤„ë°”ê¿ˆ ê°•ì œ
        body = ensure_team_line_breaks(body, home_label, away_label)

        if len(body) > max_chars + 200:
            body = body[: max_chars + 200]

        return (new_title, body)

    except Exception as e:
        print(f"[OPENAI][ANALYSIS] ì‹¤íŒ¨ â†’ simple_summarize í´ë°±: {e}")
        home_label = home_team or "í™ˆíŒ€"
        away_label = away_team or "ì›ì •íŒ€"
        core = simple_summarize(full_text_clean, max_chars=max_chars)
        body = (
            f"{home_label} & {away_label}:\n"
            f"{core}\n\n"
            "ğŸ¯ í”½\n"
            "â¡ï¸ ê²½ê¸° ì •ë³´ ì°¸ê³ ìš© í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
            "â¡ï¸ ì‹¤ì œ ë² íŒ… ì „ ë¼ì¸Â·ë¶€ìƒ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "â¡ï¸ ì„¸ë¶€ ì¶”ì²œí”½ì€ ë³„ë„ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
        return (base_title or "[ê²½ê¸° ë¶„ì„]", body)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‰´ìŠ¤ìš© Gemini ìš”ì•½ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def summarize_with_gemini(full_text: str, orig_title: str = "", max_chars: int = 400) -> tuple[str, str]:
    """
    ë‰´ìŠ¤ ê¸°ì‚¬ìš© ìš”ì•½ í•¨ìˆ˜.
    ì´ì œ OpenAI(gpt-4.1-mini)ë¥¼ ì‚¬ìš©í•´ì„œ
    'ì œëª©: ... / ìš”ì•½: ...' í˜•ì‹ìœ¼ë¡œ ë¦¬ë¼ì´íŒ…í•œë‹¤.
    """
    client_oa = get_openai_client()
    trimmed = (full_text or "").strip()
    if len(trimmed) > 6000:
        trimmed = trimmed[:6000]

    # í‚¤ ì—†ìœ¼ë©´ í´ë°±
    if not client_oa:
        print("[OPENAI][NEWS] í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ â†’ simple_summarize ì‚¬ìš©")
        fb_summary = simple_summarize(trimmed, max_chars=max_chars)
        fb_summary = clean_maz_text(fb_summary)
        return (orig_title or "[ì œëª© ì—†ìŒ]", fb_summary)

    prompt = (
        "ë‹¤ìŒì€ ìŠ¤í¬ì¸  ë‰´ìŠ¤ ê¸°ì‚¬ ì›ë¬¸ê³¼ ê¸°ì¡´ ì œëª©ì´ë‹¤.\n"
        "ì „ì²´ ë‚´ìš©ì„ ì´í•´í•œ ë’¤, ìƒˆë¡œìš´ í•œêµ­ì–´ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ 1ê°œì™€ 2~3ë¬¸ì¥ì§œë¦¬ ìš”ì•½ì„ ì‘ì„±í•´ì¤˜.\n"
        "ê¸°ì‚¬ ì•ë¶€ë¶„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ ê²ƒ.\n"
        f"ìš”ì•½ ê¸¸ì´ëŠ” ê³µë°± í¬í•¨ {max_chars}ì ë‚´ì™¸.\n"
        "\n"
        "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´:\n"
        "ì œëª©: (ì—¬ê¸°ì— ìƒˆ ì œëª©)\n"
        "ìš”ì•½: (ì—¬ê¸°ì— ìš”ì•½ë¬¸)\n"
        "ê·¸ ì™¸ì˜ ë¬¸ì¥ì€ ì¶œë ¥í•˜ì§€ ë§ˆ.\n"
        "\n"
        "===== ê¸°ì¡´ ì œëª© =====\n"
        f"{orig_title}\n"
        "\n"
        "===== ê¸°ì‚¬ ì›ë¬¸ =====\n"
        f"{trimmed}\n"
    )

    try:
        resp = client_oa.chat.completions.create(
            model=os.getenv("OPENAI_MODEL_NEWS", "gpt-4.1-mini"),
            messages=[
                {
                    "role": "system",
                    "content": "ë„ˆëŠ” ìŠ¤í¬ì¸  ë‰´ìŠ¤ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” í•œêµ­ì–´ ê¸°ìë‹¤. "
                               "í˜•ì‹ì„ ì •í™•íˆ ì§€í‚¤ê³ , ì¤‘ë³µ í‘œí˜„ì€ ì¤„ì¸ë‹¤.",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.5,
            max_completion_tokens=450,
        )
        text_out = (resp.choices[0].message.content or "").strip()
        if not text_out:
            raise ValueError("empty response from OpenAI (news)")

        new_title = ""
        summary = ""
        for line in text_out.splitlines():
            line = line.strip()
            if line.startswith("ì œëª©:"):
                new_title = line[len("ì œëª©:"):].strip(" ï¼š:")
            elif line.startswith("ìš”ì•½:"):
                summary = line[len("ìš”ì•½:"):].strip(" ï¼š:")

        if not summary:
            summary = text_out

        if len(summary) > max_chars + 100:
            summary = summary[: max_chars + 100]

        if not new_title:
            new_title = orig_title or "[ì œëª© ì—†ìŒ]"

        summary = clean_maz_text(summary)
        return (new_title, summary)

    except Exception as e:
        print(f"[OPENAI][NEWS] ìš”ì•½ ì‹¤íŒ¨ â†’ simple_summarizeë¡œ í´ë°±: {e}")
        fb_summary = simple_summarize(trimmed, max_chars=max_chars)
        fb_summary = clean_maz_text(fb_summary)
        return (orig_title or "[ì œëª© ì—†ìŒ]", fb_summary)

def summarize_analysis_from_info(
    league: str,
    home_team: str,
    away_team: str,
    kickoff_str: str,
    max_chars: int = 900,
) -> tuple[str, str]:
    """
    ì‹¤ì œ ì›ë¬¸ ë¶„ì„ê¸€ì„ ê¸ì–´ì˜¤ì§€ ëª»í•´ë„,
    'ë¦¬ê·¸ / í™ˆ / ì›ì • / ì‹œê°„' ì •ë³´ë§Œìœ¼ë¡œ
    í”„ë¦¬ë·° í˜•ì‹ì˜ ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ Geminië¡œ ìƒì„±í•œë‹¤.

    ì‹¤íŒ¨í•˜ë©´ ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ í´ë°±.
    """
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
    title_fallback = f"[{league}] {home_team} vs {away_team}".strip()

    # í‚¤ ì—†ìœ¼ë©´ í´ë°±
    if not GEMINI_API_KEY:
        body = (
            f"{league} {home_team}ì™€ {away_team}ì˜ ë§ëŒ€ê²°ì´ë‹¤. "
            f"ê²½ê¸° ì¼ì •ì€ {kickoff_str}ë¡œ ì˜ˆì •ë˜ì–´ ìˆë‹¤. "
            "ì–‘ íŒ€ì˜ ì„¸ë¶€ ì „ë ¥ ë¶„ì„ì€ ì¶”í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •ì´ë©°, "
            "í˜„ì¬ëŠ” ê²½ê¸° ì¼ì • ì•ˆë‚´ìš© í”„ë¦¬ë·° í…ìŠ¤íŠ¸ë§Œ ì œê³µëœë‹¤."
        )
        if len(body) > max_chars:
            body = simple_summarize(body, max_chars=max_chars)
        return (title_fallback or "[ì œëª© ì—†ìŒ]", body)

    # Gemini í”„ë¡¬í”„íŠ¸
    prompt = (
        "ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ì¶•êµ¬ ê²½ê¸° ë¶„ì„ í”„ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì¤˜.\n"
        "ì‹¤ì œ ìŠ¤íƒ¯ ë°ì´í„°ê°€ ì—†ì–´ë„ ì¼ë°˜ì ì¸ ì¶•êµ¬ ë¶„ì„ í‘œí˜„ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ë¡ í•´ì„œ ì¨ë„ ëœë‹¤.\n\n"
        f"ë¦¬ê·¸: {league}\n"
        f"í™ˆíŒ€: {home_team}\n"
        f"ì›ì •íŒ€: {away_team}\n"
        f"ê²½ê¸° ì‹œê°„(í‘œê¸° ë¬¸ìì—´): {kickoff_str}\n\n"
        "ìš”êµ¬ì‚¬í•­:\n"
        "- ì œëª© 1ê°œì™€ ìš”ì•½í˜• ë¶„ì„ ë³¸ë¬¸ì„ ì‘ì„±í•  ê²ƒ\n"
        "- ì œëª©ì—ëŠ” ë°˜ë“œì‹œ 'í™ˆíŒ€ vs ì›ì •íŒ€' í˜•íƒœê°€ í¬í•¨ë  ê²ƒ\n"
        "- ë³¸ë¬¸ì€ 3~6ë¬¸ì¥, ê³µë°± í¬í•¨ "
        f"{max_chars}ì ë‚´ì™¸ë¡œ ì‘ì„±í•  ê²ƒ\n"
        "- ë² íŒ… ì°¸ê³ ìš©ìœ¼ë¡œ, ì–‘ íŒ€ì˜ ìŠ¤íƒ€ì¼/ìµœê·¼ íë¦„/ì „ìˆ ì  í¬ì¸íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ë¡ í•´ ì„œìˆ \n"
        "- ì‹¤ì œ íŠ¹ì • ê²½ê¸° ê²°ê³¼ë¥¼ ë‹¨ì •í•˜ì§€ ë§ê³ , 'ìœ ë¦¬í•´ ë³´ì¸ë‹¤', 'ìš°ì„¸í•  ê°€ëŠ¥ì„±ì´ í¬ë‹¤' ì‹ìœ¼ë¡œ í‘œí˜„\n\n"
        "ì¶œë ¥ í˜•ì‹ì€ ê¼­ ì•„ë˜ì²˜ëŸ¼ë§Œ ì¨ì¤˜:\n"
        "ì œëª©: (ì œëª©)\n"
        "ìš”ì•½: (ë³¸ë¬¸)\n"
        "ê·¸ ì™¸ì˜ ë¬¸ì¥ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆ.\n"
    )

    url = (
        "https://generativelanguage.googleapis.com/v1beta/models/"
        "gemini-2.0-flash-001:generateContent"
    )
    headers = {"Content-Type": "application/json"}
    params = {"key": GEMINI_API_KEY}
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ]
    }

    try:
        print("[GEMINI][ANALYSIS] ìš”ì²­ ì‹œì‘")
        resp = requests.post(
            url,
            headers=headers,
            params=params,
            json=payload,
            timeout=20,
        )
        print("[GEMINI][ANALYSIS] HTTP status:", resp.status_code)
        resp.raise_for_status()
        data = resp.json()

        candidates = data.get("candidates") or []
        if not candidates:
            raise ValueError("no candidates from Gemini")

        parts = (candidates[0].get("content") or {}).get("parts") or []
        text_out = "".join(p.get("text", "") for p in parts).strip()
        if not text_out:
            raise ValueError("empty response")

        new_title = ""
        summary = ""
        for line in text_out.splitlines():
            line = line.strip()
            if line.startswith("ì œëª©:"):
                new_title = line[len("ì œëª©:"):].strip(" ï¼š:")
            elif line.startswith("ìš”ì•½:"):
                summary = line[len("ìš”ì•½:"):].strip(" ï¼š:")

        if not summary:
            summary = text_out

        if len(summary) > max_chars + 200:
            summary = summary[: max_chars + 200]

        if not new_title:
            new_title = title_fallback or "[ì œëª© ì—†ìŒ]"

        print("[GEMINI][ANALYSIS] ì œëª©/ìš”ì•½ ìƒì„± ì™„ë£Œ")
        return (new_title, summary)

    except Exception as e:
        print(f"[GEMINI][ANALYSIS] ì‹¤íŒ¨ â†’ í´ë°± ì‚¬ìš©: {e}")
        body = (
            f"{league} {home_team}ì™€ {away_team}ì˜ ê²½ê¸°ë‹¤. "
            f"ê²½ê¸° ì‹œê°„ì€ {kickoff_str}ë¡œ ì˜ˆì •ë˜ì–´ ìˆë‹¤. "
            "ìƒì„¸ ë¶„ì„ì€ ì¶”í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •ì´ë‹¤."
        )
        if len(body) > max_chars:
            body = simple_summarize(body, max_chars=max_chars)
        return (title_fallback or "[ì œëª© ì—†ìŒ]", body)

def extract_main_text_from_html(soup: BeautifulSoup) -> str:
    """
    mazgtv ë¶„ì„ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ ì˜ ë½‘ì•„ì„œ ë¦¬í„´.
    HTML êµ¬ì¡°ë¥¼ ì •í™•íˆ ëª¨ë¥¼ ë•Œë¥¼ ëŒ€ë¹„í•´ì„œ ì—¬ëŸ¬ í›„ë³´ ì…€ë ‰í„°ë¥¼ ì‹œë„í•˜ê³ ,
    ê·¸ë˜ë„ ì—†ìœ¼ë©´ body ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©.
    """
    # ê´‘ê³ /ìŠ¤í¬ë¦½íŠ¸ ì œê±°
    for bad in soup.select("script, style, noscript"):
        try:
            bad.decompose()
        except Exception:
            pass

    candidates = [
        "div.ql-editor",      # ì—ë””í„° ë³¸ë¬¸ì¼ ë•Œ ìì£¼ ì“°ëŠ” í´ë˜ìŠ¤
        "div.v-card__text",   # vuetify ì¹´ë“œ ë³¸ë¬¸
        "div.article-body",
        "div.view-cont",
        "div#content",
        "article",
        "main",
    ]

    for sel in candidates:
        el = soup.select_one(sel)
        if not el:
            continue
        text = el.get_text("\n", strip=True)
        if len(text) >= 200:   # ë„ˆë¬´ ì§§ìœ¼ë©´ ë³¸ë¬¸ì´ ì•„ë‹ ê°€ëŠ¥ì„±
            return re.sub(r"\s+", " ", text).strip()

    # í›„ë³´ë“¤ì—ì„œ ëª» ì°¾ìœ¼ë©´ bodyFallback
    body = soup.body or soup
    text = body.get_text("\n", strip=True)
    return re.sub(r"\s+", " ", text).strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Daum harmony API ê³µí†µ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def fetch_daum_news_json(client: httpx.AsyncClient, category_id: str, size: int = 20) -> list[dict]:
    """
    ë‹¤ìŒ ìŠ¤í¬ì¸  harmony APIì—ì„œ íŠ¹ì • ì¹´í…Œê³ ë¦¬ IDì˜ ë‰´ìŠ¤ JSON ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    (í•´ì™¸ì¶•êµ¬, KBO, í•´ì™¸ì•¼êµ¬, ë†êµ¬, ë°°êµ¬ ê³µí†µ)
    """
    if not category_id:
        return []

    base_url = "https://sports.daum.net/media-api/harmony/contents.json"

    today_kst = get_kst_now().date()
    ymd = today_kst.strftime("%Y%m%d")
    create_dt = f"{ymd}000000~{ymd}235959"

    discovery_tag_value = json.dumps({
        "group": "media",
        "key": "defaultCategoryId3",
        "value": str(category_id),
    }, ensure_ascii=False)

    params = {
        "page": 0,
        "consumerType": "HARMONY",
        "status": "SERVICE",
        "createDt": create_dt,
        "size": size,
        "discoveryTag[0]": discovery_tag_value,
    }

    r = await client.get(base_url, params=params, timeout=10.0)
    r.raise_for_status()
    data = r.json()

    contents = None
    if isinstance(data, dict):
        contents = data.get("contents")
        if contents is None:
            inner = data.get("data") or data.get("result") or data.get("body")
            if isinstance(inner, dict):
                contents = inner.get("contents") or inner.get("list") or inner.get("items")
    elif isinstance(data, list):
        contents = data

    if not contents:
        print("[CRAWL][DAUM] JSON êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìµœìƒìœ„ í‚¤:",
              list(data.keys()) if isinstance(data, dict) else type(data))
        return []

    return contents


async def fetch_article_body(client: httpx.AsyncClient, url: str) -> str:
    """
    (ì˜ˆì „ ë„¤ì´ë²„ìš©) ë‰´ìŠ¤ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ.
    í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ ë‚¨ê²¨ë‘ .
    """
    try:
        r = await client.get(url, timeout=10.0, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
    except Exception as e:
        print(f"[CRAWL][ARTICLE] ìš”ì²­ ì‹¤íŒ¨: {url} / {e}")
        return ""

    soup = BeautifulSoup(r.text, "html.parser")

    body = soup.select_one("#newsEndContents")
    if body:
        return body.get_text("\n", strip=True)

    body = soup.select_one("#newsEndBody")
    if body:
        return body.get_text("\n", strip=True)

    body = soup.select_one("#dic_area")
    if body:
        return body.get_text("\n", strip=True)

    print(f"[CRAWL][ARTICLE] ë³¸ë¬¸ ì…€ë ‰í„° ë§¤ì¹˜ ì‹¤íŒ¨: {url}")
    return ""


async def crawl_daum_news_common(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    *,
    category_id: str,
    sport_label: str,
    max_articles: int = 10,
):
    """
    Daum harmony API + HTML ë³¸ë¬¸ì„ ì´ìš©í•´ ë‰´ìŠ¤ í¬ë¡¤ë§ í›„
    êµ¬ê¸€ì‹œíŠ¸ news íƒ­ì— ì €ì¥í•˜ëŠ” ê³µí†µ í•¨ìˆ˜.
    """
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    if not category_id:
        await update.message.reply_text(
            f"{sport_label} ì¹´í…Œê³ ë¦¬ IDê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
            "ì½”ë“œ ìƒë‹¨ DAUM_CATEGORY_IDS ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
        )
        return

    await update.message.reply_text(
        f"ë‹¤ìŒìŠ¤í¬ì¸  {sport_label} ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."
    )

    try:
        async with httpx.AsyncClient(
            headers={"User-Agent": "Mozilla/5.0"},
            follow_redirects=True,
        ) as client:
            contents = await fetch_daum_news_json(client, category_id, size=max_articles)

            if not contents:
                await update.message.reply_text(f"{sport_label} JSON ë°ì´í„°ì—ì„œ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return

            articles: list[dict] = []

            # 1) JSONì—ì„œ ì œëª© + ê¸°ì‚¬ URL ì¶”ì¶œ
            for item in contents:
                if not isinstance(item, dict):
                    continue

                title = (
                    item.get("title")
                    or item.get("contentTitle")
                    or item.get("headline")
                    or item.get("name")
                )

                url = (
                    item.get("contentUrl")
                    or item.get("permalink")
                    or item.get("url")
                    or item.get("link")
                )

                if not title or not url:
                    continue

                title = str(title).strip()
                url = str(url).strip()

                if url.startswith("/"):
                    url = urljoin("https://sports.daum.net", url)

                articles.append({"title": title, "link": url})

                if len(articles) >= max_articles:
                    break

            if not articles:
                await update.message.reply_text(
                    f"JSONì€ ë°›ì•˜ì§€ë§Œ, {sport_label} ì œëª©/URL ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                )
                return

            # 2) ê° ê¸°ì‚¬ í˜ì´ì§€ ë“¤ì–´ê°€ì„œ ë³¸ë¬¸ í¬ë¡¤ë§ + ìš”ì•½
            for art in articles:
                try:
                    r2 = await client.get(art["link"], timeout=10.0)
                    r2.raise_for_status()
                    s2 = BeautifulSoup(r2.text, "html.parser")

                    body_el = (
                        s2.select_one("div#harmonyContainer")
                        or s2.select_one("section#article-view-content-div")
                        or s2.select_one("div.article_view")
                        or s2.select_one("div#mArticle")
                        or s2.find("article")
                        or s2.body
                    )

                    raw_body = ""
                    if body_el:
                        # ì´ë¯¸ì§€ ì„¤ëª… ìº¡ì…˜ ì œê±°
                        try:
                            for cap in body_el.select(
                                "figcaption, .txt_caption, .photo_desc, .caption, "
                                "em.photo_desc, span.caption, p.caption"
                            ):
                                try:
                                    cap.extract()
                                except Exception:
                                    pass
                        except Exception:
                            # selectê°€ ì•ˆ ë˜ëŠ” ê²½ìš°ëŠ” ê·¸ëƒ¥ ë¬´ì‹œ
                            pass

                        raw_body = body_el.get_text("\n", strip=True)
                    
                    clean_text = clean_daum_body_text(raw_body)
                    clean_text = remove_title_prefix(art["title"], clean_text)
                    
                    # âœ… Geminië¡œ "ìƒˆ ì œëª© + ìš”ì•½" ìƒì„± (400ì ë‚´ì™¸)
                    new_title, new_summary = summarize_with_gemini(
                        clean_text,
                        orig_title=art["title"],
                        max_chars=400,
                    )

                    art["title"] = new_title
                    art["summary"] = new_summary

                except Exception as e:
                    print(f"[CRAWL][DAUM] ê¸°ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ({art['link']}): {e}")
                    # í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œì—ë„ ìµœì†Œí•œ ë­”ê°€ ë„£ì–´ë‘ê¸°
                    art["summary"] = "(ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨)"

    except Exception as e:
        await update.message.reply_text(f"ìš”ì²­ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # 3) êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥
    client_gs = get_gs_client()
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    if not (client_gs and spreadsheet_id):
        await update.message.reply_text(
            "êµ¬ê¸€ì‹œíŠ¸ ì„¤ì •(GOOGLE_SERVICE_KEY ë˜ëŠ” SPREADSHEET_ID)ì´ ì—†ì–´ ì‹œíŠ¸ì— ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )
        return

    try:
        sh = client_gs.open_by_key(spreadsheet_id)
        ws = sh.worksheet(os.getenv("SHEET_NEWS_NAME", "news"))
    except Exception as e:
        await update.message.reply_text(f"ë‰´ìŠ¤ ì‹œíŠ¸ë¥¼ ì—´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        return

    rows_to_append = []
    for art in articles:
        rows_to_append.append([
            sport_label,      # sport
            "",               # id
            art["title"],     # title
            art["summary"],   # summary
        ])

    try:
        ws.append_rows(rows_to_append, value_input_option="RAW")
    except Exception as e:
        await update.message.reply_text(f"ì‹œíŠ¸ ì“°ê¸° ì˜¤ë¥˜: {e}")
        return

    await update.message.reply_text(
        f"ë‹¤ìŒìŠ¤í¬ì¸  {sport_label} ë‰´ìŠ¤ {len(rows_to_append)}ê±´ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
        "/syncsheet ë¡œ í…”ë ˆê·¸ë¨ ë©”ë‰´ë¥¼ ê°±ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ mazgtv ë¶„ì„ ê³µí†µ (ë‚´ì¼ ê²½ê¸° â†’ today/tomorrow ì‹œíŠ¸, JSON/API ë²„ì „) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MAZ_LIST_API = "https://mazgtv1.com/api/board/list"
# ìƒì„¸ API ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ë¨
MAZ_DETAIL_API_TEMPLATE = "https://mazgtv1.com/api/board/{board_id}"


def _parse_game_start_date(game_start_at: str) -> date | None:
    """
    '2025-11-28T05:00:00' ê°™ì€ ë¬¸ìì—´ì—ì„œ ë‚ ì§œ(date)ë§Œ ë½‘ëŠ”ë‹¤.
    """
    if not game_start_at:
        return None
    try:
        # ë’¤ì— íƒ€ì„ì¡´ì´ ë¶™ì–´ ìˆì–´ë„ ì• 19ìë¦¬ê¹Œì§€ë§Œ ì˜ë¼ì„œ íŒŒì‹±
        s = game_start_at[:19]
        dt = datetime.strptime(s, "%Y-%m-%dT%H:%M:%S")
        return dt.date()
    except Exception:
        return None


async def crawl_maz_analysis_common(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    *,
    base_url: str,        # ì´ì œëŠ” ì“°ì§€ ì•Šì§€ë§Œ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ìš©
    sport_label: str,     # ì‹œíŠ¸ì— ë“¤ì–´ê°ˆ sport (ì˜ˆ: "ì¶•êµ¬", "ì•¼êµ¬")
    league_default: str,  # Gemini í”„ë¡¬í”„íŠ¸ì— ì“¸ ê¸°ë³¸ ë¦¬ê·¸ëª… (ì˜ˆ: "í•´ì™¸ì¶•êµ¬")
    day_key: str = "tomorrow",  # "today" or "tomorrow"
    max_pages: int = 5,
):
    """
    mazgtv ë¶„ì„ í˜ì´ì§€ ê³µí†µ í¬ë¡¤ëŸ¬ (JSON API ë²„ì „).

    1) MAZ_LIST_API ì—ì„œ ë¶„ì„ ê¸€ ë¦¬ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ ê°€ì ¸ì˜¨ ë’¤,
       gameStartAt ë¬¸ìì—´ì´ 'ë‚´ì¼ ë‚ ì§œ(YYYY-MM-DD)' ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§í•œë‹¤.
    2) ê° ê²½ê¸°ì˜ idë¡œ MAZ_DETAIL_API_TEMPLATE í˜¸ì¶œ â†’ content(HTML) ìˆ˜ì§‘
    3) HTMLì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„, Geminië¡œ ìš”ì•½í•´ì„œ today/tomorrow ì‹œíŠ¸ì— ì €ì¥.
    """
    if not is_admin(update):
        await update.message.reply_text("ì´ ëª…ë ¹ì–´ëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    # í•œêµ­ ê¸°ì¤€ ë‚´ì¼ ë‚ ì§œ
    tomorrow_date = get_kst_now().date() + timedelta(days=1)
    tomorrow_ymd = tomorrow_date.strftime("%Y-%m-%d")

    await update.message.reply_text(
        f"mazgtv {sport_label} ë¶„ì„ í˜ì´ì§€ì—ì„œ ë‚´ì¼({tomorrow_date}) ê²½ê¸° ë¶„ì„ê¸€ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."
    )

    rows_to_append: list[list[str]] = []

    try:
        async with httpx.AsyncClient(
            headers={"User-Agent": "Mozilla/5.0"},
            follow_redirects=True,
        ) as client:

            # 1) ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€(1~max_pages) ìˆœíšŒ
            for page in range(1, max_pages + 1):
                # âœ… params ì“°ì§€ ë§ê³  URLì„ ì§ì ‘ ì¡°ë¦½í•´ì„œ + ê¸°í˜¸ê°€ ê·¸ëŒ€ë¡œ ê°€ë„ë¡ í•¨
                list_url = (
                    f"{MAZ_LIST_API}"
                    f"?page={page}&perpage=20&boardType=2&category=1"
                    f"&sort=b.game_start_at+DESC,+b.created_at+DESC"
                )

                r = await client.get(list_url, timeout=10.0)
                r.raise_for_status()

                # JSON íŒŒì‹±
                try:
                    data = r.json()
                except Exception as e:
                    print(f"[MAZ][LIST] JSON íŒŒì‹± ì‹¤íŒ¨(page={page}): {e}")
                    print("  ì‘ë‹µ ì¼ë¶€:", r.text[:200])
                    continue

                if isinstance(data, dict):
                    items = (
                        data.get("rows")
                        or (data.get("data") or {}).get("rows")
                        or data.get("list")
                        or data.get("items")
                    )
                else:
                    items = data

                if not isinstance(items, list) or not items:
                    print(f"[MAZ][LIST] page={page} í•­ëª© ì—†ìŒ â†’ ë°˜ë³µ ì¢…ë£Œ")
                    break

                for item in items:
                    if not isinstance(item, dict):
                        continue

                    game_start_at = (
                        item.get("gameStartAt")
                        or item.get("gameStartAtText")
                        or ""
                    )
                    game_start_at = str(game_start_at).strip()

                    # ë‚´ì¼(YYYY-MM-DD)ë¡œ ì‹œì‘í•˜ëŠ” ê²½ê¸°ë§Œ ì‚¬ìš©
                    if not game_start_at.startswith(tomorrow_ymd):
                        continue

                    board_id = item.get("id")
                    if not board_id:
                        continue

                    league = item.get("leagueName") or league_default
                    home = item.get("homeTeamName") or ""
                    away = item.get("awayTeamName") or ""

                    # 2) ìƒì„¸ í˜ì´ì§€ JSON í˜¸ì¶œ â†’ content(HTML) ì¶”ì¶œ
                    detail_url = MAZ_DETAIL_API_TEMPLATE.format(board_id=board_id)
                    try:
                        r2 = await client.get(detail_url, timeout=10.0)
                        r2.raise_for_status()
                        detail = r2.json()
                    except Exception as e:
                        print(f"[MAZ][DETAIL] id={board_id} ìš”ì²­ ì‹¤íŒ¨: {e}")
                        continue

                    content_html = detail.get("content") or ""
                    if not str(content_html).strip():
                        print(f"[MAZ][DETAIL] id={board_id} content ì—†ìŒ")
                        continue

                    # HTML â†’ í…ìŠ¤íŠ¸
                    soup = BeautifulSoup(content_html, "html.parser")
                    try:
                        for bad in soup.select("script, style, .ad, .banner"):
                            bad.decompose()
                    except Exception:
                        pass

                    full_text = soup.get_text("\n", strip=True)
                    full_text = clean_maz_text(full_text)

                    if not full_text:
                        print(f"[MAZ][DETAIL] id={board_id} ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì—†ìŒ")
                        continue

                    # 3) Geminië¡œ ì œëª©/ë³¸ë¬¸ ìš”ì•½ ìƒì„±
                    new_title, new_body = summarize_analysis_with_gemini(
                        full_text,
                        league=league,
                        home_team=home,
                        away_team=away,
                        max_chars=900,
                    )

                    rows_to_append.append([
                        sport_label,  # sport
                        "",           # id (ë¹„ì›Œë‘ë©´ ë¡œë”© ì‹œ ìë™ ìƒì„±)
                        new_title,
                        new_body,
                    ])

    except Exception as e:
        await update.message.reply_text(f"ìš”ì²­ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # ë‚´ì¼ ê²½ê¸° ë¶„ì„ì´ í•œ ê±´ë„ ì—†ìœ¼ë©´
    if not rows_to_append:
        await update.message.reply_text(
            f"mazgtv {sport_label} ë¶„ì„ì—ì„œ ë‚´ì¼({tomorrow_date}) ê²½ê¸° ë¶„ì„ê¸€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )
        return

    # 4) ì‹œíŠ¸ì— ì €ì¥
    ok = append_analysis_rows(day_key, rows_to_append)
    if not ok:
        await update.message.reply_text("êµ¬ê¸€ì‹œíŠ¸ì— ë¶„ì„ ë°ì´í„°ë¥¼ ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    reload_analysis_from_sheet()

    await update.message.reply_text(
        f"mazgtv {sport_label} ë¶„ì„ì—ì„œ ë‚´ì¼({tomorrow_date}) ê²½ê¸° ë¶„ì„ {len(rows_to_append)}ê±´ì„ "
        f"'{day_key}' ì‹œíŠ¸ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
        "í…”ë ˆê·¸ë¨ì—ì„œ ê²½ê¸° ë¶„ì„í”½ ë©”ë‰´ë¥¼ ì—´ì–´ í™•ì¸í•´ë³´ì„¸ìš”."
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¢…ëª©ë³„ (Daum ë‰´ìŠ¤) í¬ë¡¤ë§ ëª…ë ¹ì–´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# í•´ì™¸ì¶•êµ¬
async def crawlsoccer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cat_id = DAUM_CATEGORY_IDS.get("world_soccer")
    await crawl_daum_news_common(
        update,
        context,
        category_id=cat_id,
        sport_label="ì¶•êµ¬",
        max_articles=5,
    )


# êµ­ë‚´ì¶•êµ¬ (Kë¦¬ê·¸ ë“±, 5ê°œ)
async def crawlsoccerkr(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cat_id = DAUM_CATEGORY_IDS.get("soccer_kleague")
    await crawl_daum_news_common(
        update,
        context,
        category_id=cat_id,
        sport_label="ì¶•êµ¬",   # í•´ì™¸/êµ­ë‚´ë¥¼ í•œ ì¹´í…Œê³ ë¦¬ì— ë¬¶ì–´ì„œ ë³´ì—¬ì£¼ê¸°
        max_articles=5,
    )


# KBO ì•¼êµ¬
async def crawlbaseball(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cat_id = DAUM_CATEGORY_IDS.get("baseball_kbo")
    await crawl_daum_news_common(
        update,
        context,
        category_id=cat_id,
        sport_label="ì•¼êµ¬",
        max_articles=5,
    )


# í•´ì™¸ì•¼êµ¬ (MLB ë“±)
async def crawloverbaseball(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cat_id = DAUM_CATEGORY_IDS.get("baseball_world")
    await crawl_daum_news_common(
        update,
        context,
        category_id=cat_id,
        sport_label="ì•¼êµ¬",  # í•„ìš”í•˜ë©´ 'í•´ì™¸ì•¼êµ¬'ë¡œ ë¶„ë¦¬í•´ì„œë„ ê°€ëŠ¥
        max_articles=5,
    )


# ë†êµ¬
async def crawlbasketball(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cat_id = DAUM_CATEGORY_IDS.get("basketball")
    await crawl_daum_news_common(
        update,
        context,
        category_id=cat_id,
        sport_label="ë†êµ¬",
        max_articles=10,
    )


# ë°°êµ¬
async def crawlvolleyball(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cat_id = DAUM_CATEGORY_IDS.get("volleyball")
    await crawl_daum_news_common(
        update,
        context,
        category_id=cat_id,
        sport_label="ë°°êµ¬",
        max_articles=10,
    )


# 4) ì¸ë¼ì¸ ë²„íŠ¼ ì½œë°± ì²˜ë¦¬ (ë¶„ì„/ë‰´ìŠ¤ íŒì—…)
async def on_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    data = q.data or ""
    await q.answer()

    if data == "back_main":
        await q.edit_message_reply_markup(reply_markup=build_main_inline_menu())
        return

    if data.startswith("analysis_root:"):
        _, key = data.split(":", 1)
        await q.edit_message_reply_markup(reply_markup=build_analysis_category_menu(key))
        return

    if data.startswith("analysis_cat:"):
        _, key, sport = data.split(":", 2)
        await q.edit_message_reply_markup(reply_markup=build_analysis_match_menu(key, sport))
        return

    if data.startswith("match:"):
        _, key, sport, match_id = data.split(":", 3)
        items = ANALYSIS_DATA_MAP.get(key, {}).get(sport, [])

        title = "ì„ íƒí•œ ê²½ê¸°"
        summary = "í•´ë‹¹ ê²½ê¸° ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        for item in items:
            if item["id"] == match_id:
                title = item["title"]
                summary = item["summary"]
                break

        text = f"ğŸ“Œ ê²½ê¸° ë¶„ì„ â€“ {title}\n\n{summary}"

        buttons = [
            [InlineKeyboardButton("ğŸ“º ìŠ¤í¬ì¸  ë¬´ë£Œ ì¤‘ê³„", url="https://goat-tv.com")],
            [InlineKeyboardButton("ğŸ“ ë¶„ì„ê¸€ ë” ë³´ê¸°", callback_data=f"analysis_root:{key}")],
            [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
        ]

        await q.message.reply_text(text, reply_markup=InlineKeyboardMarkup(buttons))
        return

    if data == "news_root":
        await q.edit_message_reply_markup(reply_markup=build_news_category_menu())
        return

    if data.startswith("news_cat:"):
        sport = data.split(":", 1)[1]
        await q.edit_message_reply_markup(reply_markup=build_news_list_menu(sport))
        return

    if data.startswith("news_item:"):
        try:
            _, sport, news_id = data.split(":", 2)
            items = NEWS_DATA.get(sport, [])
            title = "ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
            summary = "í•´ë‹¹ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            for item in items:
                if item["id"] == news_id:
                    title = item["title"]
                    summary = item["summary"]
                    break
        except Exception:
            title = "ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
            summary = "í•´ë‹¹ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        text = f"ğŸ“° ë‰´ìŠ¤ ìš”ì•½ â€“ {title}\n\n{summary}"

        buttons = [
            [InlineKeyboardButton("ğŸ“º ìŠ¤í¬ì¸ ë¬´ë£Œì¤‘ê³„", url="https://goat-tv.com")],
            [InlineKeyboardButton("ğŸ“° ë‹¤ë¥¸ ë‰´ìŠ¤ ë³´ê¸°", callback_data="news_root")],
            [InlineKeyboardButton("â—€ ë©”ì¸ ë©”ë‰´ë¡œ", callback_data="back_main")],
        ]

        await q.message.reply_text(
            text,
            reply_markup=InlineKeyboardMarkup(buttons),
        )
        return

# í•´ì™¸ì¶•êµ¬ ë¶„ì„ (ë‚´ì¼ ê²½ê¸° â†’ tomorrow ì‹œíŠ¸)
async def crawlmazsoccer_tomorrow(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await crawl_maz_analysis_common(
        update,
        context,
        base_url="https://mazgtv1.com/analyze/overseas",  # ì´ì œëŠ” ì‚¬ì‹¤ìƒ ì˜ë¯¸ ì—†ìŒ
        sport_label="ì¶•êµ¬",
        league_default="í•´ì™¸ì¶•êµ¬",
        day_key="tomorrow",
        max_pages=5,
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹¤í–‰ë¶€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    reload_analysis_from_sheet()
    reload_news_from_sheet()

    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("myid", myid))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    app.add_handler(CommandHandler("publish", publish))
    app.add_handler(CommandHandler("syncsheet", syncsheet))
    # ë‰´ìŠ¤ ì‹œíŠ¸ ì „ì²´ ì´ˆê¸°í™”
    app.add_handler(CommandHandler("newsclean", newsclean))

    app.add_handler(CommandHandler("rollover", rollover))

    # ë‰´ìŠ¤ í¬ë¡¤ë§ ëª…ë ¹ì–´ë“¤ (Daum)
    app.add_handler(CommandHandler("crawlsoccer", crawlsoccer))             # í•´ì™¸ì¶•êµ¬
    app.add_handler(CommandHandler("crawlsoccerkr", crawlsoccerkr))         # êµ­ë‚´ì¶•êµ¬
    app.add_handler(CommandHandler("crawlbaseball", crawlbaseball))         # KBO
    app.add_handler(CommandHandler("crawloverbaseball", crawloverbaseball)) # í•´ì™¸ì•¼êµ¬
    app.add_handler(CommandHandler("crawlbasketball", crawlbasketball))     # ë†êµ¬
    app.add_handler(CommandHandler("crawlvolleyball", crawlvolleyball))     # ë°°êµ¬

    # mazgtv í•´ì™¸ì¶•êµ¬ ë¶„ì„ (ë‚´ì¼ ê²½ê¸° â†’ tomorrow ì‹œíŠ¸)
    app.add_handler(CommandHandler("crawlmazsoccer_tomorrow", crawlmazsoccer_tomorrow))

    app.add_handler(CallbackQueryHandler(on_callback))

    port = int(os.environ.get("PORT", "10000"))
    app.run_webhook(
        listen="0.0.0.0",
        port=port,
        url_path=TOKEN,
        webhook_url=f"{APP_URL}/{TOKEN}",
    )


if __name__ == "__main__":
    main()












